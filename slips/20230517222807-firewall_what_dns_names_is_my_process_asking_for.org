:PROPERTIES:
:ID:       6a115c21-0b2e-4464-883b-d7ba2466444f
:END:
#+TITLE: Firewall: what DNS names is my process asking for?
#+CATEGORY: slips
#+TAGS:

* Roam
+ [[id:265a53db-5aac-4be0-9395-85e02027e512][PF Sense]]

* Resources

+ [[https://zwischenzugs.com/2018/06/08/anatomy-of-a-linux-dns-lookup-part-i/][Anatomy of a Linux DNS Lookup]] (in four parts)
+ [[https://stackoverflow.com/questions/7842533/how-can-i-capture-network-packets-per-pid][Capture Network Packets per PID]]
  - tcpdump needs scripting/redirection if the PID hasn't already started
  - strace will [[https://bytefreaks.net/gnulinux/how-to-capture-all-network-traffic-of-a-single-process][capture traffic from a single process]]
  - tcptracer-bpfcc can also be used

* Strace

#+header: :file (or (bound-and-true-p strace-tmp-log) (setq-local strace-tmp-log (make-temp-file "galaxy-" nil ".strace")))
#+begin_src sh :results silent output file
coll=(ansible.posix ansible.netcommon ansible.utils)
coll+=(community.general kubernetes.core containers.podman community.grafana)
coll+=(community.hashi_vault community.crypto devsec.hardening)

cmd="ansible-galaxy collection install ${coll[@]}"
#strace -o galaxy-$(date +%F).strace -f -e trace=%network -s 10000 $cmd
strace -f -e trace=%network -s 10000 $cmd
#+end_src

Get uniq IP's

#+header: :var strace_tmp=(bound-and-true-p strace-tmp-log)
#+header: :file (concat strace-tmp-log ".ip")
#+begin_src sh :results silent output file
# run other block first
# don't care about ip6
ipmatch="([0-9]{2,3}\.[0-9]{2,3}\.[0-9]{2,3}\.[0-9]{2,3})"
grep -E "connect\(.*AF_INET.*inet_addr\(\"$ipmatch\"\)" $strace_tmp | \
    sed -E "s/^.*connect\(.*AF_INET.*inet_addr\(\"$ipmatch\"\).*$/\1/" | \
    nl -n rz | sort -b -k2 | uniq -f1 | sort -b -k1 | cut -f2

# hmmmmm
#nl -n rz | sort -b -k1 #| uniq -f0 #| sort -b -k1
#+end_src

Run =dig -x=

#+header: :var strace_tmp_ip=(concat strace-tmp-log ".ip")
#+header: :file (concat strace-tmp-log ".dig")
#+begin_src sh :results silent output file
# nope
# cat $strace_tmp | dig -x

# requires some cutting and formatting that i'm not doing
# dig -x -f $strace_tmp

#cat $strace_tmp_ip | xargs -I '{}' dig -x '{}'
cat $strace_tmp_ip | xargs dig -x
#+end_src

* The offending servers

#+begin_src
dig -x 172.67.68.251 52.216.49.113 52.216.82.192 54.231.161.121 52.216.135.43 52.217.201.17 52.216.160.179
#+end_src

|----------------+------------------------+------------------------|
|             ip | dns1                   | dns2                   |
|----------------+------------------------+------------------------|
|  172.67.68.251 | cruz.ns.cloudflare.com | dns.cloudflare.com     |
|  52.216.49.113 | a.root-servers.net     | nstld.verisign-grs.com |
|  52.216.82.192 | a.root-servers.net     | nstld.verisign-grs.com |
| 54.231.161.121 | a.root-servers.net     | nstld.verisign-grs.com |
|  52.216.135.43 | a.root-servers.net     | nstld.verisign-grs.com |
|  52.217.201.17 | a.root-servers.net     | nstld.verisign-grs.com |
| 52.216.160.179 | a.root-servers.net     | nstld.verisign-grs.com |
|----------------+------------------------+------------------------|

And the cloudflare servers resolved using wild-ass =*.arpa= names.

#+begin_example
251.68.67.172.in-addr.arpa
#+end_example

* A Cert Deployment Nightmare...

Oh and how do I know what =*.arpa= names are? Because I'm stubborn and crazy
enough to want =*.fdsa= [[https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiggfv7ov7-AhXoFFkFHY80BhAQFnoECA4QAQ&url=https%3A%2F%2Fwww.reddit.com%2Fr%2Fhomelab%2Fcomments%2F1113cjg%2Ftld_for_internal_use_for_ssl_certs%2F&usg=AOvVaw1oGmhvrta0r2-tmwlkL7CG][Homelab]] SSL certificates just to fuck with people and
break things.

[[https://www.rfc-editor.org/rfc/rfc8375.html][RFC 8375: *.home.arpa]] a fairly useless publically unrouted domain. If this was
machine learning, these are like the global variables you need representational
or quantum learning to adapt to. They're so universally constant that when they
change, it could result in a phase change. Here a phase change in how you see
the system of networking/dns/etc as a whole ... which is overkill to explain it,
but most people just go for LetsEncrypt, which is great, but you don't
understand what you're doing really.

Just think for a second (or a while) about what would be needed to support a
fictitious TLD across hybrid/onprem infrastructure.

+ Cert deployments
+ custom packages with your certs appended to NSS root certs
+ custom images created with that
+ confusing OCSP configs
+ very, very confused applications.

And on and on and on. These are the elements of the system you never had to
think about. Permute the things that you never thought to be a universally
constant variable and see what states emerge. It's a terrible idea, but that's
what makes it so useful.

I just wish I could actually talk to someone about these things ... but that
rarely happens ... which means /what/ ... exactly! I probably should not be
making a median income of 3,000 per year. That's what. I probably should be
mentored to develop talent, but gee I guess I'm just too pissed off about what
has happened to me ... but who wouldn't be?

* What is an enclave?

I'm pretty sure it's a buzzword because it seems like basically no one secures
subnets without just opening outbound HTTP/S sessions ... which is kinda dumb.

Granted, a reasonable solution here is permit some hosts to talk to the wider
net, make them a registry (for RPM, Galaxy, Docker, etc) and permit other
networks to talk to the trusted host. I've been over the various options [[id:fc94938a-8978-4c57-808f-4e4144626295][here]]
and elsewhere where i considered a proxy (squid) in PF Sense ... but decided
that's a terrible idea. There are other ways and GPG is reliable enough for
signatures. Still ... you just don't want to trust any old network connection
simply because something on your network told it to initiate one.

** Curl can pull tarballs from galaxy.ansible.com, but... (nope it's not that)

Ansible-galaxy cannot. Curl is not being blocked by the firewall, whereas the
=ansible-galaxy= HTTP/S flow is being sent to either:

+ dns-external-master.amazon.com
+ root.amazon.com

I think this is happening because ansible's =url.py= is somehow using
DNS-over-HTTPS, whereas =curl= needs a =doh= binary for that (?), which isn't on
my system. How curl does this is a little hard to google, since it takes you
straight to the doh project. However, given that this could be happening in the
magical middle-earth of CDN wizardry ... it's quite possibly out of my
control.

Unfortunately, my =tcpdump= and =scapy fu= just ... sucks. I'm trying to slow
down and analyze this. I'm sure there's an answer I don't know about, other than
rDNS on every other IP Address in my firewall logs.

+ Perhaps SSH Tunnel? Then log DNS somewhere else? I donno.
+ Policy-based routing via TunTap device for the process? Then my traffic and do
  packet inspection on DNS. But i need more devices on my network to do that. I
  have one router (PFSense) with four interfaces and they're occupied.

** TL;NR;

I needed some feedback, but I'm alienated ... so it . just . does not . fucking
happen quickly enough

Oh and fortunately I got it online
