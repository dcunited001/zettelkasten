:PROPERTIES:
:ID:       c79795f9-4953-4662-8177-a1d2151d62ba
:END:
#+TITLE: NixOS: Trying ROCm Tensorflow & JAX
#+CATEGORY: slips
#+TAGS:
#+PROPERTY: header-args:jupyter-python+ :kernel python3 :session /jpy::nixos_trying_rocm_tensorflow_jax
#+PROPERTY: header-args+ :var jpvol=(setq-local jpvol "/nb")
#+PROPERTY: header-args+ :var jpdir=(setq-local jpdir (expand-file-name (dc/org-roam-get-slug) jpvol))

* Roam
+ [[id:4c629c53-91b5-45eb-bb45-7dd0aca51123][Tensorflow]]
+ [[id:2049060e-6755-4a64-b295-F7B563B41505][NixOS]]
+ [[id:79d41758-7ad5-426a-9964-d3e4f5685e7e][Compute]]

* Resources
** AMD Blogs

+ [[https://github.com/ROCm/rocm-blogs/blob/3e9ad9a0f52fa029731b0978e77a6070afe542ab/blogs/artificial-intelligence/reinforcement-learning-gym/README.md][Reinforcement Gymnasium]]
+ Spack Installation includes a [[https://github.com/ROCm/rocm-blogs/blob/3e9ad9a0f52fa029731b0978e77a6070afe542ab/blogs/software-tools-optimization/spack-installation/README.md#rocm-component-dependencies][handy dependency matrix for ROCm Components]]
+ [[https://rocm.blogs.amd.com/software-tools-optimization/tf_profiler/README.html][TensorFlow Profiler in practice: Optimizing TensorFlow models on AMD GPUs]]
** Tensorflow
+ [[https://github.com/tensorflow/metadata][tensorflow/metadata]]

* Notes

** Permissions

#+begin_quote
apparently, i do _not_ need root to run the containers as such. Idk whether it's
because my user's in =video= and =render= groups ... but that would be great if that
just magically came up in coversation once in idk the past 5 or so years.
#+end_quote

Seems to run:

+ [[https://www.tensorflow.org/tutorials/quickstart/advanced][MNIST Keras API Example]]

** Babel

Currently known servers

#+begin_src emacs-lisp
jupyter-server-kernel-names
#+end_src

Server's currently known kernel names

#+begin_src emacs-lisp
(jupyter-server-has-kernelspec-p (nth 0 (jupyter-servers)) "python3")
#+end_src

Tramp url's to jupyter host can be tested with =/jpy:localhost#8888:NAME=

#+begin_quote
When connecting to an existing kernel, i.e. _when_ =NAME= in =/jpy::NAME= is the =ID= of
a kernel, the =:kernel= header argument must match the name of the kernelâ€™s
kernelspec.
#+end_quote

* K3D

write a variable

#+begin_src jupyter-python :results output file :file "img/foo.png" :async t
foo=2+2
#+end_src

#+RESULTS:

#+begin_src jupyter-python
with open("nixos_trying_rocm_tensorflow_jax.html",'w') as fp:
    fp.write(plot.get_snapshot())
#+end_src

#+RESULTS:

write an image

#+begin_src jupyter-python :results output file :file "img/foo.png" :async t
import base64
import binascii
# file :file = output
#
plot.fetch_screenshot()
print(base64.b64decode(plot.screenshot)
      # base64.decode(binascii.a2b(plot.screenshot)
      # print(f"data:image/png;base64,{plot.screenshot}")
#+end_src

* Tensorflow

#+begin_src jupyter-python :results output file :file "img/foo.png" :async t
import tensorflow as tf
print("TensorFlow version:", tf.__version__)

from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
#+end_src

#+begin_src jupyter-python :results output file :file "img/foo.png" :async t
gpus = tf.config.list_physical_devices('GPU')
if gpus:
  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
  try:
    tf.config.set_logical_device_configuration(
      gpus[0],
      [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Virtual devices must be set before GPUs have been initialized
    print(e)
#+end_src

#+RESULTS:
: 1 Physical GPUs, 1 Logical GPUs
: WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
: I0000 00:00:1767996340.596433      13 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1024 MB memory:  -> device: 0, name: AMD Radeon RX 6700 XT, pci bus id: 0000:0b:00.0

#+begin_src jupyter-python :results output file :file "img/foo.png" :async t

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
predictions = model(x_train[:1]).numpy()
tf.nn.softmax(predictions).numpy()
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
loss_fn(y_train[:1], predictions).numpy()
model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test,  y_test, verbose=2)
#+end_src

#+RESULTS:
#+begin_example
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
/usr/local/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
Epoch 1/5
2026-01-09 22:06:31.458106: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.
2026-01-09 22:06:31.707436: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1767996392.202636     959 service.cc:148] XLA service 0x7f9d1c009770 initialized for platform ROCM (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1767996392.202666     959 service.cc:156]   StreamExecutor device (0): AMD Radeon RX 6700 XT, AMDGPU ISA version: gfx1030
2026-01-09 22:06:32.214364: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Epoch 2/5
Epoch 3/5
Epoch 4/5
Epoch 5/5
313/313 - 2s - 5ms/step - accuracy: 0.9761 - loss: 0.0742
#+end_example


** GPU Memory

A little eager to eat everything

#+begin_quote
i don't have iGPU bc i thought the 5950 with 32 vCPU would be great for building
software... but i vote wrong and everyone here uses microsoft. so ya know.
#+end_quote

Anyways. Only logical devices can have policy set, but it must be set _before_
initialization.

*** Hard Limit

#+begin_src python
gpus = tf.config.list_physical_devices('GPU')
if gpus:
  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
  try:
    tf.config.set_logical_device_configuration(
        gpus[0],
        [tf.config.LogicalDeviceConfiguration(memory_limit=1024)])
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Virtual devices must be set before GPUs have been initialized
    print(e)
#+end_src

#+RESULTS:

*** Memory Growth

#+begin_src python
gpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.list_logical_devices('GPU')
    print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)
#+end_src

#+RESULTS:

* Environments
** UV
*** Setup

Setup the =pyproject.toml=

#+begin_example toml
[project]
name = "uvtf"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = []

[[tool.uv.index]]
name = "rocm-manylinux"
url = "https://repo.radeon.com/rocm/manylinux/rocm-rel-6.4"
explicity = true

[tool.uv.sources]
tensorflow-rocm = [{ index = "rocm-manylinux" }]

[dependency-groups]
dev = [
    "ipykernel>=7.1.0",
]

# uv pip install torch --torch-backend=auto
# UV_TORCH_BACKEND=auto uv pip install torch
#+end_example

Copy a template =main.py=

#+begin_src python
def main(): print("Hello from uvtorch!")
if __name__ == "__main__": main()
#+end_src

#+RESULTS:
: None

Needed to change to =python3.12= to get wheels from the =rocm/manylinux= repo


#+begin_src shell
uv pip install tensorflow-rocm==2.18.1 -f https://repo.radeon.com/rocm/manylinux/rocm-rel-6.4 --upgrade
#+end_src

#+RESULTS:

** NixOS Native

idk where to start really

** Podman
:PROPERTIES:
:header-args+: :var rocmAmdTest=(or (bound-and-true-p ob@nixos_trying_rocm_tensorflow_jax) (setq ob@nixos_trying_rocm_tensorflow_jax "/data/ml/rocm-amd-test"))
:header-args+: :var vrocm="6.4.2" vpython="3.12" vtf="2.18" vjax="0.4.35"
:header-args+: :dir (identity ob@nixos_trying_rocm_tensorflow_jax)
:END:

+ See [[https://github.com/ROCm/rocAL/blob/develop/docker/rocal-with-tensorflow.dockerfile][ROCm/rocAL docker/rocal-with-tensorflow.dockerfile]] for an example of
  extending the =Dockerfile=.
+ [[https://github.com/ROCm/rocm-blogs/blob/3e9ad9a0f52fa029731b0978e77a6070afe542ab/blogs/software-tools-optimization/tf_profiler/docker/Dockerfile][ROCm/rocm-blogs]] has an example of extending the rocm/tensorflow images to
  include =jupyterlab= with a few dependencies.
+ [[https://github.com/ROCm/taichi/commit/1a6520a533bf127e760eefdc49accfd29728cce9#diff-21cfa228c69f2aa456d76adb243bd3a9aa8e35d05cca8a18c744b354cd73c817][ROCm/taichi]] has [[https://github.com/ROCm/taichi/commit/1a6520a533bf127e760eefdc49accfd29728cce9#diff-21cfa228c69f2aa456d76adb243bd3a9aa8e35d05cca8a18c744b354cd73c817][its multi-stage build-file added here]]. it's newer builds are
  ROCm 7.0. There are plenty of examples in [[https://github.com/ROCm/taichi/tree/master/python/taichi/examples][python/taichi/examples]]
  - To circumvent the Docker/X11 thing, it is built with many multimedia
    processing capabilities. e.g. the julia set [[https://rocm.blogs.amd.com/artificial-intelligence/taichi_mi300x/README.html#rocm-taichi][mp4 video]] here (and [[https://github.com/ROCm/rocm-blogs/blob/b14966e7d36a831b44022f87d1a1501d501ad322/blogs/artificial-intelligence/taichi_mi300x/README.md?plain=1#L284-L325][source]])
  - Taichi has popup Qt plots. and jupyter's always an option, though IMO not
    ideal for interactive coding (too much scrolling, too much browser/js)

| [[https://hub.docker.com/r/rocm/jax-training][rocm/jax-training]] | includes XLA, JAX, Pytorch, TransformerEngine                   |
| rocm/rocal        | for both TF & Torch. includes magick/ffmpeg, image manipulation |
| [[https://hub.docker.com/r/rocm/jax-training][rocm/taichi]]       | processing, but with python (and mojo-style MLIR to GPU code    |
|                   |                                                                 |

*** Images

#+name: imgtf
#+begin_src emacs-lisp
;; :noweb-ref imgtf
(format "rocm/tensorflow:rocm%s-py%s-tf%s-dev" vrocm vpython vtf)
#+end_src

#+RESULTS: imgtf
: rocm/tensorflow:rocm6.4.2-py3.12-tf2.18-dev

#+name: imgjax
#+begin_src emacs-lisp
;; :noweb-ref imgjax
(format "rocm/jax:rocm%s-jax%s-py3.12" vrocm vjax vpython)
#+end_src

#+RESULTS: imgjax
: rocm/jax:rocm6.4.2-jax0.4.35-py3.12

+ Taichi Lang on ROCm installation
  - fork rocm/taichi
+ [[https://yuanming.taichi.graphics/publication/2019-taichi/taichi-lang.pdf][Taichi: High-Perf Computation on Spatially Sparse Data Structures]]
  - lots of =@ti

#+name: imgtaichi
#+begin_src emacs-lisp
(format "rocm/taichi:taichi-%s_rocm%s_ubuntu22.04_py%s" "1.8.0b1" "6.3.2" "3.10.12")
#+end_src

#+RESULTS: imgtaichi
: rocm/taichi:taichi-1.8.0b1_rocm6.3.2_ubuntu22.04_py3.10.12

*** Containers

**** Taichi

#+headers: :shebang "#!/usr/bin/env bash" :comments no :noweb yes :tangle-mode (identity #o744)
#+begin_src shell :tangle (expand-file-name "starttaichi.sh" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
shm_size=16G

# conflict: --ipc=host & --shm-size $shm_size
podman run -it --replace \
    --network=host \
    --device=/dev/kfd \
    --device=/dev/dri \
    --ipc=host \
    --group-add video \
    --cap-add=SYS_PTRACE \
    --security-opt seccomp=unconfined \
    -e 'HSA_OVERRIDE_GFX_VERSION=10.3.0' \
    -v $(pwd)/taichi/python/taichi/examples:/examples \
    -w /examples \
    --name dc-rocm_amd_taichi_test \
    <<imgtaichi()>> /bin/bash
# TODO: setup jupyter
#+end_src

Seems to work, but simulations aren't very fun without GUI

Needs X11 to be passed through to get GUI.......

#+begin_src dockerfile :tangle (expand-file-name "Dockerfile.rocm-taichi" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
FROM <<imgtaichi()>>

ARG user=appuser
ARG group=appuser
ARG uid=1000
ARG gid=1000
RUN groupadd -g ${gid} ${group} -f
RUN useradd -u ${uid} -g ${gid} -m ${user}
USER ${uid}:${gid}

# ...
#+end_src

Can't easily retrofit for =x11docker= and +can't+ definitely should _not_ pass the
wayland socket with =-u 0:1000=.

This would not be very difficult to package for nixos, actually.

**** Tensorflow

#+begin_src dockerfile :tangle (expand-file-name "Dockerfile.rocm-tf-jupyter" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
FROM <<imgtf()>>

ARG DEBIAN_FRONTEND=noninteractive

RUN pip install jupyterlab
RUN pip install k3d
RUN pip install -U tensorflow-datasets
RUN pip install matplotlib
RUN pip install -U tensorboard_plugin_profile

WORKDIR /usr/src/app
#+end_src

Clone and copy src from example

#+begin_src shell
#d=$(mktemp -d)
#git clone https://github.com/rocm/rocm-blogs $d/rcom-blogs
#cp -r software-tools-optimization/tf_profiler/src ./tf
#+end_src

#+RESULTS:

compose

#+headers: :comments no :noweb yes
#+begin_src yaml :tangle (expand-file-name "compose.yml" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
version: "3.8"
services:
  tf_prof:
    # image: <<imgtf()>>
    image: dc-tf_profiler
    container_name: dc-rocm_amd_tf_profiler
    volumes:
      - ./tf:/usr/src/app
      # - ../:/usr/src/app
    workdir: /usr/src/app
    build:
      context: .
      dockerfile: Dockerfile.rocm-tf-jupyter
    devices:
      - /dev/kfd
      - /dev/dri
    ports:
      - "8888:8888"
      - "6006:6006"
    environment:
      - "CUPY_INSTALL_USE_HIP=1"
      - "ROCM_HOME=/opt/rocm"
      - "HCC_AMDGPU_TARGET=gfx1030"
      - "HSA_OVERRIDE_GFX_VERSION=10.3.0"
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    ipc: host
    group_add:
      - video
    shm_size: 8G
    command: jupyter-lab --ip=0.0.0.0 --no-browser --allow-root --NotebookApp.token=''
#+end_src

Run tensorflow, tensorboard and jupyter

#+begin_src shell
podman compose build
podman compose up
#+end_src

Run tf only

#+headers: :shebang "#!/usr/bin/env bash" :comments no :noweb yes :tangle-mode (identity #o744)
#+begin_src shell :tangle (expand-file-name "startrocmtf.sh" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
shm_size=16G

# conflict: --ipc=host & --shm-size $shm_size
podman run -it --replace \
    --network=host \
    --device=/dev/kfd \
    --device=/dev/dri \
    --ipc=host \
    --group-add video \
    --cap-add=SYS_PTRACE \
    --security-opt seccomp=unconfined \
    -e 'HSA_OVERRIDE_GFX_VERSION=10.3.0' \
    -v $(pwd)/tf:/tf \
    --name dc-rocm_amd_tf_test \
    <<imgtf()>> /bin/bash
#+end_src

No AVX512?! watt?! (seriously though. binary open/close, erode/dialate can
benefit from that... but i'm thinking about things in)

#+begin_quote
2026-01-08 08:38:54.125807: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
#+end_quote
**** JAX

#+headers: :comments no :noweb yes
#+begin_src yaml :tangle (expand-file-name "jax-compose.yml" ob@nixos_trying_rocm_tensorflow_jax) :noweb yes
version: "3"
services:
  rocm:
    image: <<imgjax()>>
    container_name: dc-rocm_amd_jax
    # ports:
    #   - "8080:80"
    environment:
      - "CUPY_INSTALL_USE_HIP=1"
      - "ROCM_HOME=/opt/rocm"
      - "HCC_AMDGPU_TARGET=gfx1030"
      - "HSA_OVERRIDE_GFX_VERSION=10.3.0"
    volumes:
      - $(pwd)/tf_jax:/tf_jax
#+end_src

running from script

#+headers: :shebang "#!/usr/bin/env bash" :comments no :noweb yes :tangle-mode (identity #o744)
#+begin_src shell :tangle (expand-file-name "startrocmjax.sh" ob@nixos_trying_rocm_tensorflow_jax)
shm_size=16G

# conflict: --ipc=host & --shm-size $shm_size
podman run -it --replace \
    --network=host \
    --device=/dev/kfd \
    --device=/dev/dri \
    --ipc=host \
    --group-add video \
    --cap-add=SYS_PTRACE \
    --security-opt seccomp=unconfined \
    -e 'HSA_OVERRIDE_GFX_VERSION=10.3.0' \
    -v $(pwd)/tf_jax:/tf_jax \
    --name dc-rocm_amd_jax_test \
    <<imgjax()>> /bin/bash
#+end_src

quick tests

#+begin_src shell
python3 -c "import jax; print(jax.devices())" # [RocmDevice(id=0)]
python3 -c "import jax.numpy as jnp; x = jnp.arange(5); print(x)" # [0 1 2 3 4]
#+end_src

Not dynamically MLIR'ing anything yet though
