:PROPERTIES:
:ID:       258fd4df-5aa1-4747-a470-5feb2f977c92
:END:
#+TITLE: Centos: resize a Luks-encrypted LVM volume
#+CATEGORY: slips
#+TAGS:  

* Roam
+ [[id:bdae77b1-d9f0-4d3a-a2fb-2ecdab5fd531][Linux]]
+ [[id:ca4acf9b-775b-4957-b19a-0988b7f429c5][rpm]]
+ [[id:d7cc15ac-db8c-4eff-9a1e-f6de0eefe638][File Systems]]
+ [[id:24c5cf12-0f0e-412b-9574-6190769b3223][LUKS]]
+ [[id:95146708-4046-4cdb-a5df-e15594f17733][Bootloader]]


* Problem

Need an extra 1TB SSD disk for the Dell Poweredge, but too many are allocated
to bare metal Centos. I no longer need to use the baremetal server to host a
Docker and RPM repositories... so I can downgrade this from a 1TB to a 500GB.

#+begin_quote
I'm not really sure why literally no one includes instructions for on-premises
installs behind firewalls. Kubernetes, K3S, Rancher, Longhorn, Vault, Saltstack,
etc are exceptions to that, but almost zero linux guides even come close to
describing how to split out image/package management onto local repositories,
which is kinda sad -- if you simply pass all your port 80:443 traffic to
indeterminate "metalinks", then i'm sorry, that's terrible.

Of course, you can always let the "cloud" manage the complexity for you.
#+end_quote

Even though i shouldn't be poor, I am. So I run regularly run through shit like
this. While I wish I could say that the experience is worth it ... it's not.
Apparently, experience doesn't pay anything and farming in Diablo 2, Act 1 gets
you nothing -- except maybe Secret CoW level, which I'm pretty sure is a
Copy-On-Write joke.

It's crazy what the "Digital Age" has brought us -- such marvels as TikTok and
Vine ... but apparently the nerds are too busy "engineering" and wearing capes
to notice the plebs burning everything down.

* Solution

Using this [[https://www.golinuxcloud.com/linux-move-directory-to-another-partition/#Step_7_Manage_SELinux_Optional][article as a guide]].

Download a similar ISO (Fedora 37 in this case). Once booted:

+ copy public keys to =~/.ssh/authorized_keys=
+ cut off public internet
+ configure ssh-agent/yubikey/pkcs-11 on another machine
+ ssh

** Useful commands

+ e2fsck
+ resize2fs
+ sfdisk
+ cfdisk
+ lsblk
+ cryptsetup (resize)
+ pvdisplay
+ pvresize
+ pvs/vgs/lvs
+ dmsetup [status|info]
+ dmsetup remove [lv/vg] # then cryptsetup close

** Disk Layout

*** Original

Now I'm guessing that swap needs to be resized too ... hmmmm.

+ /dev/sda3 :: mapped as =cryptroot=
+ /dev/sdb1 :: mapped as =cryptdata=
+ /dev/sdd3 :: ampped as =newroot=

#+begin_example
sda              259:0    0  114.4G   0 disk
├─sda1           259:1    0   600M    0 part  /boot/efi
├─sda2           259:1    0   1G      0 part  /boot
└─sda3           259:2    0   116.8G  0 part
  └─cryptlvm     254:0    0   116.8G  0 crypt
    ├─cs-swap    254:1    0   7.8G    0 lvm   [SWAP]
    ├─cs-home    254:1    0   39G     0 lvm   /home
    ├─cs-root    254:2    0   70G     0 lvm   /
sdb              259:0    0   931.5G  0 disk
└─sdb1           259:2    0   700G    0 part
  └─cryptlvm     254:0    0   700G    0 crypt
    ├─ds-data    254:1    0   700G     0 lvm   /data
#+end_example

*** Final

Moving everything to a "500 GB" SSD under a single LUKS volume

#+begin_example
sdd              259:0    0  465.8G    0 disk
├─sdd1           259:1    0   600M     0 part  /boot/efi
├─sdd2           259:1    0   1G       0 part  /boot
└─sdd3           259:2    0   464.2G   0 part
  └─cryptlvm     254:0    0   464.2G   0 crypt
    ├─cs-swap    254:1    0   7.8G     0 lvm   [SWAP]
    ├─cs-home    254:1    0   39G      0 lvm   /home
    ├─cs-root    254:2    0   70G      0 lvm   /
    ├─cs-data    254:2    0   100%FREE 0 lvm   /data
#+end_example


** Resize old LUKS

*** Resize Ext4

Easy enough. Check partition layout with =cfdisk=

ExtFS needs to be checked first ... just in case?

#+begin_src bash
e2fsck -f /dev/mapper/cryptroot
#+end_src

Resize to the new extents. =cfdisk= can also do a pretty good job of taking care
of the partitions

#+begin_src bash
resize2fs -p /dev/mapper/cryptroot $NEWSIZE
#+end_src

Smaller disk sizes will make the transfer quicker. It can be reinflated later.

#+begin_quote
Bonus points: It gets you a defragged filesystem for free ... but you don't care
about cylinder math do you?
#+end_quote

*** Resize LV

Since this saves on transfer time:

#+begin_src shell
lvresize /dev/ds/data -r -L $NEWSIZE
#+end_src

=lvs=, =vgs=, =pvdisplay -m $LUKS= and =pvresize $LUKS= will help here.

**** TODO update after figuring out how to move LV to new VG (i just used dd)

*** Resize PV/VG

Resize the physical volume

#+begin_src shell
pvresize -v /dev/mapper/
#+end_src

** Copy partition table

Backup old partition table from =/dev/sda=.

#+begin_src shell
sfdisk -d /dev/sda > part_table
#+end_src

Restore it to the new disk =/dev/sdd=

#+begin_src shell
sfdisk /dev/sdd < part_table
#+end_src

It updates the new disk with the old size. Dump disk size from new disk

#+begin_src shell
sfdisk -d /dev/sdd | grep -i last-lba | cut -f2 -d' ' >> part_table
#+end_src

Manually edit and replace the value for =lba-last=, the rewrite the partition
table. As long as the existing partitions begin/end on the same sectors, then
this won't erase any data.

I also needed to change the lba-first from =37= to =2048=.

Now run =sfdisk /dev/sdd < part_table=

** Resize partition table

The new disk will now have lots of free space. You could fix this using =sfdisk=
but it's easier to just use =cfdisk=. Resize the partition and accept the
default value or do some sector math and calculate it exactly.

Before doing this, if hibernate or bad blocks from swap are important, then
you'll want to move the swap to a new location. I'm not aware of how blocks are
allocated in LVM, so bad blocks may not be as much of a problem so long the
logical volume is created/moved occasionally.

** Move Disks from old =cs= volume group

If the old LUKS container and it's LVM is mounted at the same time, its names
conflict with the new group. Ensure that =dmsetup= reports these devices are
completely removed before running =cryptsetup= to map =newroot=

#+begin_src shell
dd of=/dev/sda1 if=/dev/sdd1 bs=1M status=progress
#+end_src

**** TODO dd commands used to move non-LUKS partitions

**** TODO dd commands to move LUKS partition

**** TODO test LUKS partition, =cryptsetup=

** Create new LV for =ds-data=

Resize PV to LUKS-crypted partition extents

#+begin_src shell
pvresize /dev/mapper/newroot
#+end_src

Create new LV

#+begin_src shell
lvcreate -n data -l 50%VG cs
#+end_src

** Move Disks from old =ds= volume group

Ensure both the =cryptdata= LUKS container is setup Just use =dd= then reinflate the ext4 filesystem

**** TODO dd command

**** TODO resize2fs command

* Manage Disk UUID's

This was noted after completing the initial test chroot. I anticipated UUID
issues, which is why i was going to reboot and rechroot without the former disk,
but I didn't expect it immediately.

#+begin_quote
There's a lot of good interview question material here.
#+end_quote

Changing the UUID's is necessary as soon as possible. The metadata for changes
to VG/PV/LV keys on UUID's, so if there are duplicate UUID's that map PV's to
VG's, then the LV's associated to this will disappear without the original
disk...

... even though it managed to move the partition correctly? The new LV should have
a separate UUID though.

** Three ways to move forward

You'll have to decide on how to manage the UUID's. Since the =/dev/sdd*= table,
partitions and LUKS container images were copied over, you can only safely
change the boot/efi/luks container (which will require updating =/etc/fstab= in
chroot). However, after opening the luks container, it will be necessary to
identify the metadata mappings and manually change them. I don't think that LVM
VG/LV's link to the LUKS UUID, but the PV probably does.

1. You can take a backup of the LVM metadata created by the changes for both
   LUKS containers (old & new: =/dev/sda3= and =/dev/sdd3=)
   - from here, you can diff the two files, expect to edit the metadata backup
     to restore it later
   - did you know: windows can't diff files /or file trees/ without WSL; you
     need an app for that
   - perhaps no need for tune2fs
2. You can use tune2fs to change UUID's now, but you have to manage metadata now
   - both of the first two will involve two copies of the metadata, manually
     editing UUID's using commandline tools (or by editing the metadata backup
     file)
3. it may be possible to use =dd= over SSH & network socket, in which case, there
   is no real UUID problem, since the metadata is on two systems.
   - it may also be possible to deal with this using iSCSI, but it's likely
     you'll still encounter UUID issues there.

* Rebuild the system to launch on the new disks

For chroot, i'm referencing [[https://wiki.archlinux.org/title/chroot][archwiki]] though Centos/RHEL likely have their own
tools ... but the way these tools mask implementation details is why i'm
referencing the archwiki. So...

** Setup a chroot to the new volume

Since the partition disk was copied, these UUID's should be the same ... not
sure where the problems end there but it certainly includes booting!

#+begin_src shell
newbootUUID=$(blkid -o value -s UUID /dev/sdd2)
newefiUUID=$(blkid -o value -s UUID /dev/sdd1)
#+end_src

Since the =/etc/fstab= declares root disks with UUID, it may be smart to remove
this (or [[https://linuxconfig.org/how-to-retrieve-and-change-partitions-universally-unique-identifier-uuid-on-linux][use tune2fs to change partition UUID]]) before anything gets mounted
automagically. At this point, the original disks are no longer needed, but
should be retained.

Mount root disk.

#+begin_src shell
newroot=/mnt/centosroot
mkdir $newroot
cryptsetup open /dev/sdd3 newroot
mount /dev/mapper/cs-root $newroot
#+end_src

Make a copy of =/etc/fstab=. Note any special options or BTRFS subvolumes there.

#+begin_src shell
cp $newroot/etc/fstab $newroot/etc/fstab.bak
#+end_src

Mount pseudo file systems and devices

#+begin_src shell
mount -t proc /proc $newroot/proc
mount -t sysfs /sys $newroot/sys
mount -o bind /dev $newroot/dev
mount --rbind /sys/firmware/efi/efivars $newroot/sys/firmware/efi/efivars
# cp /etc/resolve.conf $newroot/etc/resolve.conf
#+end_src

Mount other disks

#+begin_src shell
mount /dev/sdd2 $newroot/boot
mount /dev/sdd1 $newroot/boot/efi
mount /dev/mapper/cs-home /home
mount /dev/mapper/cs-data /data
#+end_src

After finishing partitions/disks, then setup chroot to the new root volume on
=/dev/sdd3= and mount them.

#+begin_src shell
chroot $newroot /bin/bash
#+end_src

** Reboot to clear out the system

That tested that chrooting was possible. Reload the system and insert the disks
to avoid UUID issues ...

... but it's too late, the VG/LV mappings were written to the wrong disks/volumes.

*** Fetch LV metadata from other disk

Since this is a live ISO, the LVM backup/metadata is no longer accessible.
Without the metadata on the disk (there is apparently none of it at the metadata
layer) it doesn't matter much that the PE blocks for the PV contain the LV
images.

** Update Bootloader & init

Centos boots with systemd and requires running dracut to rebuilt initramfs

** Update SELinux metadata
