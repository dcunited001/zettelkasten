:PROPERTIES:
:ID:       5d6a495e-944c-40e8-8bcb-03431ccee353
:END:
#+TITLE: Sitemap analysis
#+CATEGORY: slips
#+TAGS:
#+PROPERTY: header-args:jupyter-python :session jupyter-python-862e00a2b12f2b60040ac00a7e4d6abc

+ Mostly following this guide on =advertools= from [[https://www.semrush.com/blog/content-analysis-xml-sitemaps-python/][this semrush blog]].
+ I also found this post on medium about destructuring URLs into a graph to
  visualize: [[https://towardsdatascience.com/analyze-and-visualize-urls-with-network-graph-ee3ad5338b69][Analyze and visualize URLs with Network Graph]]

[[file:img/python-sitemap.png]]

* Environment setup

The kernel isn't running under the =pyenv= environment.

#+BEGIN_SRC jupyter-python :results output silent
!pip install advertools polars plotly
#+END_SRC

#+BEGIN_SRC jupyter-python
##!pip list
!pyenv which pip
#+END_SRC

+ Can run commands like =(jupyter-repl-associate-buffer CLIENT)= to reassoc the
  kernel to the buffer, but this is not =jupyter-org= per se.
+ Can also run the =jupyter-lab= process in a shell, then run =M-x
  jupyter-server-list-kernels= which will walk you through token auth. This
  helps to get the =:kernel= parameter set above.
+ It doesn't seem to be working for some reason

#+BEGIN_SRC jupyter-python
# import advertools as adv
import plotly.graph_objects as go
import polars as pl

TEST_SITEMAP="https://www.nova-labs.org/sitemap.xml"
#nova_siteindex=adv.sitemap_to_df(TEST_SITEMAP)
#pd

#+END_SRC

* Roam
+ [[id:b4c096ee-6e40-4f34-85a1-7fc901e819f5][Python]]
+ [[id:8f115e56-56e7-447f-8f38-02e65db2a67a][Google Analytics]]
