:PROPERTIES:
:ID:       eeaf988f-664c-4e2c-8790-8de63a965da1
:END:
#+TITLE: Math: Path Signature Applied For Great Machine Learns
#+CATEGORY: slips
#+TAGS:

* Roam
+ Math
+ Data Science

* Resources

** An overview

[[https://github.com/kormilitzin/the-signature-method-in-machine-learning][kormilitzin/the-signature-method-in-machine-learning]]: A good overview of links
to the application of signatures, including:

+ [[https://arxiv.org/pdf/1405.4537.pdf][Rough paths, Signatures and the modelling of functions on streams]] connects
  path signatures all the way through utilizing the moments to measure the
  "peculiarity" of a path (e.g. how well does it fit the known variance here or
  here)
+ [[https://arxiv.org/pdf/1603.03788.pdf][A Primer on the Signature Method in Machine Learning]]
+ [[A Primer on the Signature Method in Machine Learning][Kernels for sequentially ordered data]]

** Python

*** [[github:patrick-kidger/signatory][patrick-kidger/signatory]]

[[https://signatory.readthedocs.io/en/latest/][docs]]

This library includes CPU/GPU implementations of the =signature= and
=logsignature= algorithms

+ Using with gaussian processes: [[https://arxiv.org/abs/1906.08215][Bayesian
  Learning from Sequential Data using Gaussian Processes with Signature
  Covariances]]
  - probably worth it just for the appedicies.
+ Using with sequentialized kernels: [[https://jmlr.org/papers/v20/16-314.html][Kernels for Sequentially Ordered Data]]

**** Calculating dimension

Simple answers to "[[https://signatory.readthedocs.io/en/latest/pages/examples/simple.html][how big is that shit anyways]]"

#+begin_src python
import torch
import signatory
# Create a tensor of shape (2, 10, 5)
# Recall that the order of dimensions is (batch, stream, channel)
path = torch.rand(2, 10, 5)
# Take the signature to depth 3
sig = signatory.signature(path, 3)
# sig is of shape (2, 155)
#+end_src

+ For sequences of 10 points
+ sampled from a channel of $x \in \Bbb{R}^5$
+ gives a dimension of 50

Its path signature to depth $k = 3$ will have dimension of =155=

*** [[github:datasig-ac-uk/esig][datasig-ac-uk/esig]]

[[https://esig.readthedocs.io/en/latest/][docs]]

*** [[github:bottler/iisignature][bottler/iisignature]]


* Path Signatures

By reframing a problem in terms of a controlled differential equation, you can
summarize a the evolution of continuous function in terms of a path signature
along a much smaller set of points. While the path signature is generated using
something that resembles the exterior algrebra and explodes in complexity, the
total dimensionality can be less than treating points sampled along the
continuous function -- without loss in granularity.

The path signature is generated from a Tensor algebra across several samples of
a function.

The continuous function is constrained in a similar way to that of a polynomial
for which you specify the N roots. However, since the "exterior algebraic"
components of the path signature combinatorically enumerate constraints on the
areas/volumes, then a small number of dimensions can significantly constrain the
function space of polynomials that could correspond to those values.

So if $x_1, x_2, x_3$ and $y_1, y_2, y_3$ correspond to the the typical x,y,z
for some function's domain/range across time steps $t \in [0,1,2,3,..]$, then
the path signature captures details about:

+ $dy_1, dy_2, dy_3$ w.r.t $dx_1, dx_2, dx_3
+ but also $(dy_1 * dx_2)$ w.r.t $dx_1$ and $dx_2$ and so forth (like the
  exterior algebra)
+ but this process also iterated on different ranges of timesteps: so if
  considering overlapping sequences $0 \leq t < 2$ and $1 \leq t < 3$ and so
  forth.

This gives rise to a feature space that you can train ML to recognize.

** Application to ML Time Series

#+begin_quote
The grand questions for me:

For ASL, do I need any path signatures for all the Mediapipe coordinates? Or
just the fingers?

What shapes do my tensors need to be? And how do I make them smaller. I only
have one good GPU and this thing's supposed to run on a phone. Kaggle already
crippled the requirements -- since they think the solution they have in mind all
that's needed.

If I'm summarizing the mediapipe coordinates w.r.t. barycentric coordinates
representing a nice "centure of the palm" how does this translate to the
coordnate tracking of fingers (and the path signatures thereof)
#+end_quote

I've somewhat answered these questions for myself by reading[fn:pathsig] ... but
it's still not clear just how big we're talking about. And are there better
optimizations.

It's clear that this can't be combined (at least not trivially) with Riemannian
optimization methods

** Calculating Dimensionality

* Videos

** [[https://www.youtube.com/watch?v=pkZhtscaX1M&t=12s][Signature Methods for Time Series Data (Sam Morley 2022)]]

Also Oxford.


Provided you already understand a bit about what you're getting into, then this
video provides a great summary of the method, the indexes and the integrals.

[[./img/shuffle-product-levy-area.png]]

This picture from the slides may originally be from "Dev. the Path Sig
Methodology" [fn:pathsig] or it this may not be its first appearance. It's a
little hard to Google Levy Area's though.

Slides: [[https://github.com/inakleinbottle/talks/blob/9e6cdcb74dae62767a851194530fca6bcbdb6aa6/signatures-methods-for-time-series-data.pdf][inakleinbottle/talks]]

** [[https://www.youtube.com/watch?v=Lj_vs0nq1NA][Path Signatures in Topology, Dynamics and Data (Oxford 2022)]]

This talk is quite deep and starts off in the deep end. Provided you don't need
floaties to deal with what comes later (maybe just a body board), then you'll be
alright: it gets easier, but the depth at the outset is worth it when it all
comes together.

*** Loop Spaces and the Topology thereof

Esp. compared to the topology of the manifold upon which the Loop space is based

Attempting to study these spaces leads to the deRham complex via the use of
Differential Formsin an attempt to compute the cohomology groups so ...  yeh I
know of deRham's complex (sharps, flats and technicalities of differentiation),
but I don't know how to use it.

Nanda emphasizes what KT Chen published in 1951 about differential graded
algebra, summarized in this [[https://doi.org/10.1090/S0002-9904-1977-14320-6][1977 publication from KT Chen]]. Here grades are
simply ways of organizing spaces by complexity, say the grades of the tensor
algebra. Typically when an object from Tensor calculus can be refactored or
restructured into a sum, then if the sum can be stated in terms of an index
itself then these are "grades".

**** Graded Algebras

The Tensor power:

\(
T^kV = V^{\otimes k} = V\otimes V \otimes \cdots \otimes V
\)

The Tensor Algebra, a direct sum of grades.

\(
T(V)= \bigoplus_{k=0}^\infty T^kV = K\oplus V \oplus (V\otimes V) \oplus (V\otimes V\otimes V) \oplus \cdots.
\)

#+begin_quote
A.K.A. the free algebra, free as in "there's always money in the banana stand"
... j/k  (latex ripped from wikipedia here)
#+end_quote

So in the above, the second power $V^{\otimes 2}$ constitutes the relationships
that are captured by most kernel methods: they are usually quadratic.

**** Grades in Geometric Algebra

In geometric algebra, the blades are also arranged according to grades, all in
all forming two pyramids where the indexes in the top/bottom result from
pascal's triangle. The power of GA is in the relationships between objects at
each level and between objects of various levels. It is similar to methods used
in path signature or even in exterior algebra, but is based on a more
generalized set of bases

[[./img/ga-grades.png]]

*** Iterated Integrals and Shuffle products

Here Nanda defines a more abstract notion of the iterated integrals. This is
usual for pure math, but not for data science.

In the application of the path signature method, the relationship between
shuffle products, Levy Area's and the grades of interated integrals is critical
-- exploiting the properties of the Shuffle Product provides a basis for
shortcuts in computations. See "Dev. the Path Sig Methodology" [fn:pathsig]

*** Welcome to the USS Enterprise, Capt Picard

After feeling like got beamed out to the wrong quadrant, it all comes together.

#+begin_quote
"iff if is Lipschitz" -- don't cut the red wire. that's about all i know
#+end_quote

And now we get to the formulation of Controlled Diff EQ's, complete with a
formulation of the CDE in matrix representation, which is closing in on what's
needed for an ML application.


**** TODO Glorious Properties

+ This is the section containing
+ Also revisit notes on the above sections

**** TODO Topological Data Analysis, Barcodes, Stability Thm, Landscape Embedding

+ maybe reference oliver knill's paper(s) requiring combinatorial enumeration of
  simplicial complices

These are all pretty amazing techniques, but require a shitton of computational
power. Some of them less so, once the data is collected. e.g.

+ barcodes, etc can be searched once an "index" is generated. however, the
  nature of ML pipelines means that real-time applications are right out.
+ Also, the techniques favor reasonably discretized spaces -- kinda useless (or
  at least outcompeted) on spaces of discrete values, but also incomputeable on
  "real" euclidian spaces.
  - This could probably be replaced by or extracted from clustering of some kind
    (look at the MAPPER algorithm for inspiration, maybe).
  - The specific sphere size used for the functional analysis technique
    generating the simplicial complices is a hyperparameter which is
    computationally hard to reevaluate (that might ideally be more of an
    ellipse). it's probably hard to reasonably guess a useful value for this
    sphere without already having most of your data to reflect on, but you can't
    know the outcome of using a specific sphere size. in computer graphics,
    things like quadtrees/octtrees are used instead.


* References

[fn:pathsig]

2017 [[https://arxiv.org/abs/1707.03993][Developing the Path Signature Methodology and its Application to
Landmark-based Human Action Recognition]]

This is the paper that I originally referenced when learning this, but some of
the videos were helpful in understanding the indexes for integrals.

[fn:alg1004]

2020 [[https://dl.acm.org/doi/pdf/10.1145/3371237][Algorithm 1004: The Iisignature Library: Efficient Calculation of
Iterated-Integral Signatures and Log Signatures]]

A paper on iisignature python library
