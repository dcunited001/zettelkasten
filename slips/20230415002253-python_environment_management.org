:PROPERTIES:
:ID:       a5886419-b2dd-4a02-a91d-0bc392fb3b88
:END:
#+title: Python: Environment Management

Everytime I revisit this, it improves significantly ... but it's still a mess
for someone who hasn't coded a lot of python.

But it's honestly not that bad. There's just a lot of ecosystem sprawl and it's
hard to assess with zero name-recognition to any of it.

[[file:img/python_environment.png]]

It's a well-known issue: see [[https://drewdevault.com/2021/11/16/Python-stop-screwing-distros-over.html][Python: Please stop screwing over Linux distros]],
but honestly it's improved a lot. It mostly results from a combination of
python's popularity, a notebook's need for version-specific requirements and
python's ubiquity, being essential to modern linux/mac systems. This last point
means containerization and locked dependencies are essential.

I've solved this two times in the past two years, only to lack sufficient time
to work with notebooks. Google Colab works well, but lacks the speed/flexibility
& precision I need when the notebook requires external services.  And I've
probably worked though this ten times in the past ten years as the norms shifted
through:

+ vm/linux/mac
+ virtualenv
+ docker: storage requirements are annoying and maintaining image persistence
  through system reinstalls is a bit of a problem (i was really too
  unemployed/isolated to even use Docker, though I initially used it in 2013)
+ pipenv/etc
+ back to virtualenv, since it's core
+ oh poetry: looks a little too high-level essential
+ guix profile + pipenv: works until you need multiple python versions?
+ hmmm oh, poetry! but it doesn't work well for notebook dependencies

You may find some simple solution where you never really have the need for
precision/reproducibility in python environments ... if you're not using tools
like the following,

+ Blender-as-a-Module
+ Tensorflow with CUDA
+ The fucking =LD_LIBRARY_PATH= and =patchelf= thing
+ Builds of Atlas/Lapack, perhaps using AMD's AOCC compiler/optimizer

I think the answer for me in 2023 is just =virtualenv + direnv=, perhaps
including the possibility for poetry where it's found in a package.

Oh and I really don't like jupyter notebooks. The benefits and caveats are
similar to those for "literate programming" -- they're great when you want to
communicate your work or in other limited use cases. But I need autocompletion
and I like REPL's -- oh and brittle/new OS installs basically break anything and
duct tape connecting your editor to your python environments. With guix/nix, you
/maybe/ take slower steps forward, but you basically never take steps backwards.

I guess I basically need a scheme for naming/organizing notebook environments.

* Direnv + Venv

** Pros
+ Simple and very core.
+ Direnv is a self-contained Go library, with emphasis on "self-contained."

** Cons
+ Doesn't necessarily handle Python environments.

* Poetry ([[https://python-poetry.org/docs/][docs]])

Nice when working on packages. IMO, doesn't really work with notebook
environments.

** Pros
+ suffient containerization

** Cons
+ A little cumbersome, especially when managing Guix & Arch envs
+ a new abstraction set has appeared.

* Guix

If I were working with python often and using Guix, I would create something
like a single channel that only has Guix/Nonguix as channel dependencies.

** Pros
+ Totally reproducible environments

** Cons
+ Guix python packages are old. This is in the "cons" for me, but is not too bad
  in itself.

* Nix

** Pros
+ Combines well with poetry using [[https://github.com/nix-community/poetry2nix][nix-community/poetry2nix]]

** Cons
+ Requires Nix, which IMO has advantages/disadvantages wrt Guix.
+ I don't have Nix on my systems. Perhaps in the future.

* Pipenv ([[https://pipenv.pypa.io/en/latest/index.html][docs]])

** Pros
+ Works alright.
+ It's a fairly thin set of tools, reuses existing abstractions, mostly.

** Cons
+ A little cumbersome, especially when managing Guix & Arch env

* Docker

** Pros
+ Works well, even for complex GPU things when AUR can't get you a =clinfo= that
  works ...
+ The Docker transient buffers in emacs are very helpful. ALL of the commands
  are logged.


#+begin_quote
it's complicated, I know... sometimes it be like that, sometimes it do ... i've
been here before.
#+end_quote

** Cons

+ Requires planning (paths, volumes, mounts).
+ A little messy. Requires upkeep
+ Usually requires more knowledge about your builds
+ Your projects can't easily be integrated into one another.

* An example of "simple" project gone wrong

#+begin_quote
i guess the underlying issue here is that I don't know what questions to ask
people when I have a chance ... well that and programmers kinda want each other
to independently find answers.

we just had a docker meetup. i had no idea i'd be using docker three days
later. lol
#+end_quote

I build mediapipe over here, but =clinfo= don't work on my host system ... so
now I need it over there, but it's a complicated Bazel project. If possible, I'd
like it like it to bring its build artifacts over there, hopefully with the
C/C++ =compile_commands.json= in tact.

Now, I'm new at this Bazel and C/C++ thing. I don't know what I'm doing, but I
just found out that =clangd= drops down to the =/usr/lib= folders and that Linux
is basically a giant IDE ... so understandably I'm a little shook right now.

#+begin_quote
because how have I not spent enough time around people to figure ... sorry, IRC
and chat helps a ton, but it's not like spending a lot of time in person ... i
need to be around people who can see me making mistakes that I don't know to ask
about
#+end_quote

Now I used to think that LSP on Kubernetes would be a good idea, but then I
recently decided that was bollocks ... but here I am, full circle. Anyways, I'm
kinda joking. I always assumed that C/C++ was difficult to develop for
(isolated/hermetic builds are important, but that can be pushed to automated
workflows if necessary), but apparently it's a bit more lightweight than I
thought ... at least until you need to specify build flags. And this mediapipe
bazel project needs 'em (I think)

Anyways, to build mediapipe, it needs Tensorflow (GPU if possible). I want
Python libs for LSP. I think that's easy enough, but the codes gotta live
somewhere and if I need to pull down the C/C++ as well, the python code might as
well live there too. So what we've got here is a catch-22.

The AMD Tensorflow image needs to be provided to the Mediapipe Dockerfile --
since I can't build native at the moment and not that I want to. This need to
write a Dockerfile is great if it works, but I bet it doesn't work 100% of the
time and when it doesn't, I won't immediately know why. So, add some checks to
the whole process: image versions in the Dockerfile need to be pinned to stable?

So i've gone back and forth:

#+begin_quote
jedi? pyenv? venv? python-lsp? the other
python-lsp? pyright? is this pywrong? what about EIN? there's no way that still works.
#+end_quote

And yeh ... if you would say "just use this or that, linux or mac, just use
VSCode", it might help a tiny amount by making decisions for you ... however, it
doesn't shield you from the complexity inherent in the processes. You need
files, you need build artifacts, the processes your editor fires up need to have
the workspace loaded: you could use any editor for that and it's still
complicated.

And that all said, I really do love being wrong about this because holy crap, if
I have to get stuck working in a single programming language simply because its
ecosystem locks you in ... well then at least it's not javascript. Again, i'm
mostly joking here and I must be "doing it wrong".

The C/C++ levels of Tensorflow and Mediapipe aren't 100% necessary ... until
they are. If I have to solve it correctly for the build, its artifacts, my
personal filesystem/services and my emacs/python/eglot config -- well I better
remember how I did it and i better reinforce that habit frequenty in the short
term..

The reasons I'm concerned about the C/C++ layers

+ Because I may actually want to debug code or I may actually need to create
  custom Tensorflow layers/etc
+ I also may want to include Rust or C/C++ programs as part of my kaggle
  submission -- since they may run 10x faster. And if so, I need control over
  the build config to produce bins on/for the Kaggle environment: Xeon, nVidia
  Tesla P100 and/or TPU.

Regardless, it is at least something to consider, not that I have "submission
requirement" problems yet -- but everyone else does and chances are, they're
better than me at this or at least more productive.

If it were up to me, I'd go back in time, make zig a lisp and write it with
that, but we can't have nice things (one of these days, i'll actually learn or
appreciate why a lisp can't have that level of performance)
