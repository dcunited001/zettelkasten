:PROPERTIES:
:ID:       46931a16-3896-45b9-9fca-a0c94ee94266
:END:
#+TITLE: Finance: Historical Data Backends
#+CATEGORY: slips
#+TAGS:

* Resources

** Lists

+ [[https://github.com/wilsonfreitas/awesome-quant][wilsonfreitas/awesome-quant]]

** Projects

+ [[github:microsoft/qlib][microsoft/qlib]]
+ [[https://github.com/JerBouma/FinanceDatabase][JerBouma/FinanceDatabase]] CSV Database containing historical records
+ [[https://github.com/JerBouma/FinanceToolkit][JerBouma/FinanceToolkit]] Toolkit for fetching new data
+ [[https://quantecon.org/projects/][QuantEcon]]
+ [[https://wesmckinney.com/book/][Python for Data Analysis]]

+ [[github:llazzaro/analyzer][llazzaro/analyzer]]
+ [[github:llazzaro/pystock][llazzaro/pystock]]

*** Numerai

+ [[https://docs.numer.ai/numerai-tournament/readme][Numerai Datasets]]
+ [[https://github.com/numerai/numerapi][numerai/numerapi]] API to numerai

** Data Sources

*** IEX Cloud

A product with a free plan, but docs that indicate the underlying schemata

+ [[https://iexcloud.io/documentation/using-core-data/using-normalized-financial-data.html][Normalized Financial Symbols]]
  - [[https://iexcloud.io/documentation/reference/financial-identifiers.html][Financial identifier types]]
  - [[https://iexcloud.io/documentation/using-core-data/finding-symbols.html][Finding Symbols]]

6 Supported Symbols:

| CUSIP         | FIGI                   | ISIN                          |
| Nasdaq (INET) | Refinitiv PermID alpha | RIC (Reuters Instrument Code) |

*** Fama/French

+ [[https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html][Fama/French Data Library]]
+ [[https://famafrench.readthedocs.io/en/latest/gettingstarted/gettingstarted.html][famafrench.py]]: import/build data sets ([[https://famafrench.readthedocs.io/en/latest/applications/applications.html][applications/examples]])

[[https://en.wikipedia.org/wiki/Capital_asset_pricing_model][Three-factor and Five-factor models]] that built on [[https://en.wikipedia.org/wiki/Capital_asset_pricing_model][CAPM]] to balance investment
portfolios or to rank stock selections.

**** Portfolio Optimization

These models are mentioned in a video on [[https://www.youtube.com/watch?v=sXYW0KgCKbE&t=1620s][Conditional Portfolio Optimization]] as
useful features for ranking stocks. They're used in combination with other
market/macro features and looking at cross/correlation between investments
indexes/industries.

The approaches mentioned in this video are along the lines of what I was
thinking. Some significant differences: I would be gradually building small
selections of investments, I'm looking for a human-in-the-loop approach and I
want results/insights to be simply explainable.

** Schema

*** Options

**** From [[https://github.com/chrischow/open_options_chains][chrischow/open_options_chains]]

Blog: [[https://chrischow.github.io/dataandstuff/2022-01-13-open-options-chains-part-i/][Towards Open Options Chains: A Data Pipeline for Collecting Options Data At Scale - Part I]]

+ Compares various data pipelines for assembing a database of options chains data
+ Describes a pipeline using Apache Airflow to import data into postgres
+ Many, many references listed that are worth a look (also there are 5 parts to the series)
+ options schema [[https://github.com/chrischow/open_options_chains/blob/main/src/open_options_chains.py][here]]
+ also wrote [[https://chrischow.github.io/agamotto/][agamotto]] which tracks status of options trading strategies (and
  finds interesting plays?)

*** Time Series

+ r/influxdb: [[https://www.reddit.com/r/influxdb/comments/kuzxo2/comment/giwdfax/?context=3][Schema for Stock Option Database]]
  - References: [[https://medium.com/coinograph/storing-and-processing-billions-of-cryptocurrency-market-data-using-influxdb-f9f670b50bbd][InfluxDB to store/process billions of Crypto data]]

** Papers

+ [[http://dx.doi.org/10.14419/ijet.v7i3.13.16344][Data Warehouse Based Modelling Technique for Stock Market Analysis]]
+ [[https://arxiv.org/pdf/2009.11189.pdf][Qlib: An AI-oriented Quantitative Investment Platform]]

* Finance Database/Toolkit



* Modeling

Regardless of how much buzz there is for Finance/ML and how many videos/posts
there are on it, finding information on schemas for collating data retrieved
from various API's is pretty sparse. If you don't have a backend for historical
data, how are you going to do anything useful at scale with finance data that is
(1) not ad hoc and (2) involves features that you pass to analysis or ML?

** Schema Extraction

*** From Swagger

So each of these API's has an OpenAPI/Swagger JSON. These API responses can be
stored as-is, but they cannot be queried on unless the data sources have been
collated (viz. homogenized into a common format). There must be at least be
common id's and hashes shared between the historical data sets.

**** TODO find resources for transforming subsets of swagger specs into somewhat normalized fields


** Data Models By Context

The security symbols are simple strings that are fairly universal

*** Quants

*** Securities

These are usually data streams,

**** Symbols

These need to be keyed by the exchange/context where there might be duplicates
across multiple exchanges. e.g.

+ Forex symbols when trading
+ Commodity symbols when trading/pricing on a specific commodity exchange
+ Crypto symbols when trading/pricing on a

Furthermore, these symbols also need to be keyed across exchanges because the
exchanges

**** Stocks

**** Options

**** Crypto

**** Forex

**** Futures

These can be commodity-based

**** Bonds

Keys:

+ issuer

+ [[https://dba.stackexchange.com/questions/24956/how-to-design-a-database-for-financial-bond-prices][How to design a database for financial bond prices?]]

*** Fundamentals

*** SEC/Filings

** Data Modeling Approaches

*** OLAP

[[https://en.wikipedia.org/wiki/OLAP_cube][OLAP Cubes]] typically include indexes/columns based on [[https://en.wikipedia.org/wiki/Fact_table][facts]] and [[https://en.wikipedia.org/wiki/Dimension_(data_warehouse)#Dimension_table][dimensions]]. They
let you track aggregate values across time, which is esp. useful when it is
difficult/impossible reconstruct those queries in the future.

#+begin_quote
A fact table typically has two types of columns: those that contain facts and
those that are a foreign key to dimension tables.
#+end_quote

Examples of data you may pull down that would work well when keyed on dimension
data:

+ Stock prices on a minute by minute basis

*** Time Series

* Roam
+ [[id:fecf9468-ffb8-4f9d-9816-b10568c5afe8][Finance]]
+ [[id:73aee8fe-b894-4bda-a9b9-c1685d3249c2][SQL]]
+ [[id:0b80782f-92a8-4b48-958c-a41e7ff8713e][Data Lake]]
