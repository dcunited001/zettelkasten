:PROPERTIES:
:ID:       2b7dae76-003f-4714-b621-c046d855fe3e
:END:
#+TITLE: Ansible: setup a portable environment on Guix
#+CATEGORY: slips
#+property: header-args            :tangle-mode (identity #o400) :mkdirp yes
#+property: header-args:conf       :tangle-mode (identity #o600) :mkdirp yes
#+property: header-args:sh         :tangle-mode (identity #o500) :mkdirp yes
#+property: header-args:shell      :tangle-mode (identity #o500) :mkdirp yes
#+property: header-args:scheme     :tangle-mode (identity #o500) :mkdirp yes
#+property: header-args:emacs-lisp :tangle-mode (identity #o600) :mkdirp yes
#+TAGS:

The most recent version of this is probably in my dotfiles as [[https://github.com/dcunited001/ellipsis/tree/master/ANSIBLE.org][ANSIBLE.org]]. It
generates a project, still not sure whether I want it there or not. I'd rather
use =guix deploy=

* Org Babel Config

Ensure the values below are set. They're required for the =:tangle= output
paths. The emacs-lisp blocks below are used further down . If emacs is already
open, then running =M-: (setenv "VAR" "value")= will set the environment var for
the whole process. This is also useful for setting:

#+begin_src emacs-lisp
(setq-local ansible-prefix (or (getenv "ANSIBLE_PREFIX") "build/ansible")
            org-confirm-babel-evaluate nil)
#+end_src

I am building to another directory for now (not in my dotfiles), but I may
switch to =./build/ansible= later.  I like maintaining a layer of separation
here because it's much less likely that I'll commit something I don't intend to,
which for better or worse happens less frequently than it may seem. I'm not sure
there are any secrets in my repos unless in the git index somehow, but I've
always staged by line/hunk ... so.

** Build

The intent here is to build a portable ansible config at =ansible-prefix=.  When
tangling to paths other than =ansible-prefix= and =.config/ansible=, everything
sticks to =FHS= and =XDG= for clarity.

+ .local/bin :: scripts that exec
+ .local/lib/ansible :: scripts that source

Generally, most ansible project files will be generated in =.config/ansible= and
can then be copied into =ANSIBLE_HOME= when needed.

*** Don't Stow It

+The build can be dumped into a folder or stowed:+

Probably don't do this, since it's already difficult enough to gitignore
things (I could use a bit of feedback from time to time)

#+begin_src sh
ANSIBLE_HOME=$HOME/.ansible
stow --dir $ANSIBLE_PREFIX --target $ANSIBLE_HOME
#+end_src

Anything that ends in =*.eg= or contains =*.eg.*= is added to the stow ignore list:

#+begin_src conf
# perl regex
*.eg
*.eg.*
#+end_src

Stowing into the =$ANSIBLE_HOME= might not work out, since it contains
directories like:

+ collections
+ roles
+ plugins
+ tmp
+ galaxy_cache
+ pc
+ ANSIBLE_PLAYBOOK_DIR

* Environment

Ensure =ANSIBLE_HOME= is set. Almost everything will be relative to that.

Depending on its value and whether a config file is read, then files will likely
be created in =$HOME/.ansible/tmp= and =$XDG_CONFIG_HOME/ansible=.

Using direnv can help jump between various ansible projects. If you set
=ANSIBLE_CONFIG=, it's very likely that you'll want multiple configs like
=ansible.debug.cfg= so use =-c $config= to do that.

#+begin_src sh :tangle (expand-file-name ".envrc.eg" ansible-prefix)
export ANSIBLE_HOME=$PWD
export ANSIBLE_CONFIG=$ANSIBLE_HOME/ansible.cfg

# probably don't use emacsclient to edit your vault
export EDITOR=vi
PATH_add bin

use_guixs --search-paths -L $HOME/.dotfiles/dc -L $HOME/.dotfiles/ellipsis -m manifest.scm
# use_guix_manifest manifest.scm

# ansible binaries are in .venv
export VIRTUAL_ENV=.venv
layout python3
#+end_src

** Python

An additional =.venv= profile could be set up for other environments like VS Code.

After the =.venv= profile is created, run the following

#+begin_example shell
pip install --upgrade pip
pip install -r requirements.txt
#+end_example

The requirements file has been generated from:

#+begin_src sh
pip install ansible-core ansible-builder ansible-navigator ansible-lint \
    ansible-pylibssh yamllint dnspython passlib netaddr pysocks httpx
# pip install kubernetes # installs kubectl for kubernetes.core.*
#+end_src

** Guix Profile

See "Ansible On Guix" for info on its dependencies. The =venv= above is required
to get =ansible= and other tools like =ansible-navigator=

I'm only using this for =packer=. Manually add this to the project. Tangling
into dotfiles makes Guix assume that it should interpret it as a scheme file.

#+begin_src scheme :tangle (expand-file-name "manifest.scm" ansible-prefix)
(specifications->manifest
  '("packer-bin"
    "terraform-bin"
    ;; pkg-config: adds PKG_CONFIG_PATH for libvirt-python
    "pkg-config"
    "libvirt"))
#+end_src

The source for the package is in my dotfiles. This is the equivalent inline
definition.

#+begin_src scheme
(define-module (ellipsis packages terraform)
  #:use-module ((guix licenses) #:prefix license:)
  #:use-module (guix gexp)
  #:use-module (guix utils)
  #:use-module (guix download)
  #:use-module (guix packages)
  #:use-module (guix build-system copy)

  #:use-module (gnu packages base)
  #:use-module (gnu packages compression)

  #:use-module (srfi srfi-1))

;; NOTE may require ~/.config customization, esp for plugins
(define-public packer-bin
  (package
    (name "packer-bin")
    (version "1.9.2")
    (source (origin
              (method url-fetch)
              (uri (string-append "https://releases.hashicorp.com/packer/"
                                  version "/packer_"
                                  version "_linux_amd64.zip"))
              (sha256
               (base32 "0xbjjkknv6bvgh6j8dyfjf0d1sbwvf0vb8yq2npp15prsp84izil"))))
    (build-system copy-build-system)
    (inputs (list unzip))
    (arguments
     '(#:install-plan '(("packer" "bin/"))))
    (home-page "https://www.hashicorp.com/products/packer")
    (synopsis "Packer standardizes and automates the process of building
images")
    (description "Packer is a tool for creating identical machine images for
multiple platforms from a single source configuration.")
    (license license:mpl2.0)))

(define-public terraform-bin
  (package
    (name "terraform-bin")
    (version "1.5.4")
    (source (origin
              (method url-fetch)
              (uri (string-append "https://releases.hashicorp.com/terraform/"
                                  version "/terraform_"
                                  version "_linux_amd64.zip"))
              (sha256
               (base32 "1skps2scfjl2d3iqxj7j76rkrry0wyllr8fgm0kz9xzc6x8w1n8n"))))
    (build-system copy-build-system)
    (inputs (list unzip))
    (arguments
     '(#:install-plan '(("terraform" "bin/"))))
    (home-page "https://www.hashicorp.com/products/terraform")
    (synopsis "Infrastructure automation to provision and manage resources in any cloud or
data center")
    (description "Terraform enables you to safely and predictably create, change, and improve
infrastructure. It is an open source tool that codifies APIs into declarative
configuration files that can be shared amongst team members, treated as code,
edited, reviewed, and versioned.")
    (license license:mpl2.0)))
#+end_src

The package spec may be out of sync until I have a Guix channel up

+ This workflow requires signed commits, which implies that you have CI/CD that
  invokes =guix build= and other tools before the packages are available through
  your channel.

For =manifest.scm=

+ you can use =guix transformations= to select branches/patches or specify =-L
  $loadpath= and pull in modules if your codebase is clean.
+ For local development you can always define packages inline.

** Emacs

*** Ansible LSP

This will set =*.yml= buffers to be loaded with =ansible-mode=

#+begin_src emacs-lisp  :tangle (expand-file-name ".dir-locals.eg.el" ansible-prefix)
((auto-mode-alist . (("\\.yml\\'" . ansible-mode)))
 (nil
  . ((eglot-workspace-configuration
      . (:ansible
         (:validation
          (:enabled t :lint (:enabled t))))))))

;; ((yaml-mode . ((flycheck-checker . 'yaml-yamllint))))
#+end_src

Ansible LSP will silently fail if options like =ansible-lint= are enabled with
an invalid path. This config explicitly defines all the paths and disables
validation/linting. Ansible LSP doesn't have =-h= or =--help= options to
document CLI functionality and doesn't send data to =stderr= afaik.

#+begin_src emacs-lisp
((nil ((eglot-workspace-configuration
        . (:ansible
           (:ansible (:path "/mnt/secrets/ansible/.venv/bin/ansible"))
           (:python
            (:interpreterPath "/mnt/secrets/ansible/.venv/bin/python3"))
           (:validation
            (:enabled nil :lint
                      (:enabled nil :path "/mnt/secrets/ansible/.venv/bin/ansible-lint"))))))))
#+end_src

An additional mode descending from =yaml-mode= _may be_ needed to ensure that
eglot is sending buffers to the LSP server to be interpreted as =:ansible=
buffers.

#+begin_src emacs-lisp
(define-derived-mode ansible-mode yaml-mode "Ansible"
  "Major mode which is YAML-mode + ansible minor mode."
  (ansible))
#+end_src

**** LSP Docker

I tried getting this to work in a docker container, but the in-project and
in-container paths don't match. The =lsp-mode.el= package handles this with
=lsp-docker=, but it can still represent a lot of configuration overhead for
some projects.

It may be possible if using =docker-tramp=, but you must interact with the
project as though it's remote.

Since Ansible LSP may run EE containers, it would break that functionality
... unless ...  =¯\_(ツ)_/¯=

#+begin_quote
There is always a way... SMH
#+end_quote

** VS Code

I must have missed the Guix =vscodium= package or decided to try the flatpak.

** Ansible

*** Execution Environment

A custom EE is needed for Kubernetes & Helm dependencies when running from Guix

Docs:

+ Ansible Controller [[https://docs.ansible.com/automation-controller/latest/html/userguide/execution_environments.html][Execution Environments]]
+ [[Ansible execution environment images for ][Ansible EE Images for Airgapped Environments]]: unnecessary here, but airgapped
  guides are generally great resources for mapping out everything "you don't
  need to know about [yet]"

**** Helm EE

When building Helm charts, at least some network state will probably need to be
passed or fetched. I'll probably thin it out later.

#+begin_src yaml :tangle (expand-file-name "ee/helm-env.eg.yml" ansible-prefix)
version: 3

images:
  base_image:
    # centos stream doesn't have helm (repology says no one does)
    name: quay.io/fedora/fedora:39

dependencies:

  python: ../requirements.txt
  python_interpreter:
    package_system: python39
    python_path: /usr/bin/python3.9

  # yamllint dnspython passlib
  # [ansible-]pylibssh
  # python-kubernetes

  # this has a github dependency, so a separate req.yml is needed
  # galaxy: ../requirements.yml
  galaxy:
    collections:
      # basic
      - name: community.general
      - name: ansible.posix
      - name: ansible.netcommon
      - name: ansible.utils
      - name: fedora.linux_system_roles

      # container/vm
      - name: kubernetes.core
      - name: containers.podman
      - name: community.grafana
      - name: community.libvirt

      # networking
      - name: cisco.ios
      - name: pfsensible.core

      # security
      - name: community.hashi_vault
      - name: community.crypto
      - name: devsec.hardening

  system:
    - helm # [platform:rpm]

  ansible_core:
    package_pip: ansible-core==2.15.0
  ansible_runner:
    package_pip: ansible-runner==2.3.3

  # ansible==8.0.0
  # ansible-compat==4.1.2
  # ansible-core==2.15.0
  # ansible-pylibssh==1.1.0

# options:
#   skip_ansible_check: False # default
#   tags: # throws an error
#    - ansible-helm-env:latest

additional_build_files:
  - src: ./ansible.cfg
    dest: configs

additional_build_steps:
  prepend_base:
    - RUN echo This is a prepend base command!
    # potentially enable package repos, update CA or modify system state here.

  prepend_galaxy:
    - ADD _build/configs/ansible.cfg /etc/ansible/ansible.cfg

  prepend_final:
    - RUN whoami
    - RUN cat /etc/os-release

  append_final:
    - RUN echo This is a post-install command!
#+end_src

***** EE Ansible.cfg

This could drift (like everything else)

#+begin_src conf :tangle (expand-file-name "ee/helm-env.eg.yml" ansible-prefix)
[defaults]
nocows=1
# inventory=inventory.yml
transport=ssh
filter_plugins=plugins/filter

[inventory]
any_unparsed_is_failed=True

#+end_src

**** Testing Helm Image

#+begin_src sh
ansible-navigator exec --ee true --eei ansible-helm-env:latest "helm --help"
#+end_src

**** Sharing Sockets

Depending on how badly you'd like to expose secrets on disk, then you may want
to share GPG sockets with the container:

+ You probably don't though, do you?
+ Because that's a pretty bad idea isn't it?
+ You'd just rather have vault in a cluster, wouldn't you?
+ ... yeh, you probably would.

How to do this? It's not worth it, but I try explaining [[https://github.com/dcunited001/zettelkasten/blob/master/slips/20230726211109-containers_sharing_unix_sockets.org][here]] anyways.

**** Verifying Signatures

I was going to just pass a keyring with the main sigs to the =ansible-builder=
to refer to later. However signing really is just employed for closed settings &
networks. See [[https://www.ansible.com/blog/digitally-signing-ansible-content-collections-using-private-automation-hub][Digitally Signing Ansible Content Collections]], which is some quick
scripts to build the keyring.

#+begin_example shell
# signatures: []
cat ./collections/ansible_collections/*info/GALAXY.yml | grep signatures
#+end_example

*** Vault

**** Using Your Host OS Keyring

See vault-keyring-client.py in [[github:ansible-community/contrib-scripts][ansible-community/contrib-scripts]]

**** GPG-Protected Vault Password

If you're using a Yubikey for GPG, you can also use it to encrypt your Ansible
Vault password.

***** Using File Descriptors

Invoke the playbook command like this:

#+begin_src sh
ansible-playbook -i inventory.yml --vault-pass-file <(gpg -d mypass.gpg) tasks/foobar.yml
#+end_src

I'm not super confident in using file descriptors to protect the password, so
there's another way you can use

***** Using A Script

From [[https://gitlab.com/tomaskadlec/ansible-vault-gpg][gitlab.com/tomaskadlec/ansible-vault-gpg]].

Set this in your =ansible.cfg=

#+begin_example conf
vault_password_file=bin/vaultgpgpass
#+end_example

Create a script, ensure it has the =#!/bin/sh= directive and chmod it.

#+begin_src
#!/bin/sh
gpg --batch --use-agent --decrypt mypass.gpg
#+end_src

It will follow whatever policies your agent sets. This could be script that
makes a call to unix =pass= as well.

*** Ansible Navigator

[[github:ansible/ansible-navigator][ansible/ansible-navigator]] is a TUI for exploring the local ansible
environment. It launches automations via a docker container by default.

#+begin_src yaml :tangle (expand-file-name ".config/ansible/ansible-navigator.eg.yml" ansible-prefix)
---
ansible-navigator:
  editor:
    command: gmacsclient -nw {filename} +{line_number}
    console: true
#+end_src

Judging by the source, opening a file in =$EDITOR= doesn't allow you to save
changes, meaning you'll have to save over the file in its path. The app is for
quick exploration of a project or environment, which it does well.

To run any ansible commands, by default, it uses the
=ghcr:io/ansible/creator-ee:v0.17.0= image.

**** Using the GPG Vault Script

Passing the password to the Navigator environment requires running with =mode:
stdout=, which makes it less of a TUI. You can get around this with aliases and
multiple Navigator configurations, but that's a hassle.

Using the GPG Vault Script above requires disabling the EE Container, as it has
a separate GPG agent. The only way to address that is by creating a custom
container or a volume with the GPG agent config, then making your local GPG
agent socket accessible from within the EE container. I wouldn't recommend
that...

Add the following to your =ansible-navigator.yml=

#+begin_example yaml
---
ansible-navigator:
  execution-environment:
    enabled: False
  ansible:
    cmdline: --vault-password-file bin/vaultgpgpass
#+end_example

If you set a conflicting value for =vault_password_file= in =ansible.cfg=, you
can override it here or pass =ANSIBLE_VAULT_PASSWORD_FILE== to empty it out.

#+begin_example yaml
ansible-navigator:
  mode: stdout
  enable-prompts:
  execution-environment:
    enabled: True
  ansible:
    cmdline: --vault-ask-pass
#+end_example

You could override it as an ENV var to pass it to the EE container. This has
potential problems, though you should already trust your EE container.

+ AFAIK you can only pass the gpg protected password by forwarding a socket
+ you can set =ANSIBLE_VAULT_PASSWORD_FILE= in the environment passed to EE, but
  you have to set ={ enable-prompts: true, mode: stdout }=

*** Ansible support script

These aliases provide some useful reminders of important CLI options.

#+begin_src sh :tangle (expand-file-name ".local/lib/ansible/init_ansible.eg.sh" ansible-prefix)
alias ansplay="ansible-playbook -i inventory.yml --vault-pass-file <(gpg -d vault.gpg)"
alias ans="ansible -i inventory.yml --vault-pass-file <(gpg -d vault.gpg)"

# ansbuild -f ee-helm.yml
# alias ansbuild="ansible-builder -t 'ans-ee:latest' --prune-images"
alias ansbuild="ansible-builder build --prune-images --context ee/build -t ansible-helm-env:latest"

#alias ansnav="ansible-navigator -i inventory.yml --vault-pass-file <(gpg -d pass.gpg)"

ansnav() {
  local command=${1:-welcome}
  local inventory=${2:-inventory.yml}
  local vault_file=${3:-vault.gpg}
  ansible-navigator $command -i $inventory --vault-pass-file <(gpg -d $vault_file)
}
#+end_src

+ I'm not too worried about posting the GPG usage, since I'm not so sure that
  relying on GPG/Yubikey to protect secrets is viable.
+ It probably won't work when you're on a team, but for me, I don't need network
  services at the moment to
+ However secrets are provided, the method needs to work for =ansible=,
  =terraform=, =packer= and other tools, but many of these require
  containers/VM's in their workflow.
+ If you're not relying on the network -- firewall, services, authentication,
  etc. -- you're probably doing it wrong. It's basically impossible to secure
  workstations without shifting the burden to the network.

* Ansible

** Config

Some naïve example settings:

#+begin_src conf :tangle (expand-file-name ".config/ansible/ansible.eg.cfg" ansible-prefix)

[tags]

[defaults]
nocows=1

# * inventory
inventory=inventory.yml

# * playbooks

# * facts

# gather_subset=

# * logs

# ** logs: options

# ** logs: ansible validation

# ** logs: yaml validation

# ** logs: jinja2 validation

# * auth

# ** vault

# ** connection
transport=ssh

# * roles & collections

# * modules & module_utils

# * plugins

# ** filters

# ** group vars:

# ** plugin paths

# * [defaults]

[privilege_escalation]


[persistent_connection]


[connection]


[ssh_connection]

# for multiplexed SSH connections (ssh can reconnect for 5 minutes)
ssh_args=-o ControlMaster=auto -o ControlPersist=300
control_path=%(directory)s/ansible-ssh-%%r@%%h:%%p
control_path_dir=.ssh/sockets

[colors]


[selinux]


[diff]


[galaxy]

display_progress=True


[inventory]

any_unparsed_is_failed=True

[netconf_connection]


[paramiko_connection]


[jinja2]

#+end_src

*** Comparing against defaults

Run to generate defaults and diff.

#+begin_src sh :results output silent :file (expand-file-name ".config/ansible/ansible.cfg.defaults" ansible-prefix)
ansible-config init --disabled -t --format=ini
#+end_src

The =--format env= option can be evaluated or appended to a =.envrc=.

*** Dumping configs

Here the formats are json, yaml, or ini and are incompatible with the above, though

#+begin_src sh
ansible-config dump -c $config --only-changes -t --format=$format
#+end_src

** Plugins

#+begin_example conf
# [callback_slack]
# channel = #thechannel
# username = fdsa
# webhook_url = env:SLACK_WEBHOOK_URL

# [callback logstash]
# port = env:LOGSTASH_PORT
# server = env:LOGSTASH_SERVER
# type = env:LOGSTASH_TYPE
#+end_example

*** TODO include other collections/roles paths?


*** PFSense Lookup Plugin

To show docs on the =pfsensible.core.pfsense= lookup plugin, run =ansible-doc -t
lookup pfsensible.core.pfsense=

The =pf.yml= file describes network topology/state and is required to use the
lookup plugin. An example is available in the docstrings at the =pfsense.py=
link. Four sections are required in =pf.yml=:

+ pfsenses
+ rules
+ hosts_aliases
+ ports_aliases

Since the plugin source contains a =main()= and whatnot, then once the plugin is
set up, you can run command's like what's below. This allows you to quickly dump
the state.

#+begin_src sh
pfpath=collections/ansible_collections/pfsensible/core/plugins/lookup
$pfpath/pfsense.py pf.yml pf1
#+end_src


**** TODO fix description:
+ [ ] copy to lookup_plugins
+ [ ] install dnspython

To make the [[https://github.com/pfsensible/core/blob/master/plugins/lookup/pfsense.py][pfsense.py]] lookup plugin available to run as a script, either:

+ copy the lookup plugin =$pfpath/pfsense.py= to =./lookup_plugins=
+ or append the plugin's path within your =collections= directory to the
  =lookup_plugins= path in your =ansible.cfg=.
+ use =ansible-runner run -m pfsense= but you'll need to fix the module path. i
  couldn't get this to work and needed to move on. there aren't many examples of
  using =ansible-runner= where a script is run with =main()=


** Inventory

An example of inventory.

#+begin_src conf :tangle (expand-file-name ".config/ansible/inventory.eg.yml" ansible-prefix)
all:
  ansible_port: 2020
  # ansible_user: ansible
  # ansible_host: 123.123.123.123
  hosts:
    host1.local:
      ansible_user: root
    host2.local:
      ansible_user: ansible
    vm1.vm.local:
      ansible_user: ansible
    guix1.vm.local:
      ansible_user: ansible
    router1.net.local:
      ansible_user: admin
    router1.net.local:
      ansible_user: admin
    host1.k3s.local:
      ansible_user: ansible
    vm1.cloud.com:
      ansible_user: ansible

  children:
    cisco:
      # TODO: shell-only
      hosts:
        router1.net.local:
          ansible_user: ansible

    ddwrt:
      # TODO: ash only (not bash)
      hosts:
        router2.net.local:
          ansible_user: admin

    guix:
      ansible_python_interpreter: /run/current-system/profile/bin/python3
      hosts:
        host2.local:

    centos:
      hosts:
        host1.local:

    vm:
      hosts:
        vm1.vm.local:
        vm2.vm.local:
          ansible_python_interpreter: /run/current-system/profile/bin/python3

    # kubernetes example at https://github.com/techno-tim/k3s-ansible
    k3s:
      hosts:
        host1.local:
#+end_src

And then =group_vars/*.yml=, though =system_timezone= should be fetched
dynamically and stored as a fact.

#+begin_src yaml :tangle (expand-file-name ".config/ansible/group_vars/all.yml" ansible-prefix)
---
system_timezone: "America/New_York"

#+end_src

To see the hostvars applied to a group, use the =debug= module

#+begin_src sh
group=all

# for all vars
ansible $group -m debug -a "var=hostvars"

# for a specific var inherited from a group
ansible $group -m debug -a "var=system_timezone"
#+end_src


* Setup

** External Services

*** Galaxy

Getting access to Galaxy from behind a firewall is kind of a mess. It works
occasionally, but there's quite a bit of CDN magic that happens. You'll need a
mirror. However ... and I don't know why I didn't just switch gears earlier
... you can just pop the controller off the subnet. A protected Ansible AWX
would be a bit different. See the =pulp/pulp_

The Ansible Galaxy url's are nice and mnemonic: =galaxy.ansible.com/$namespace/$collection=

#+begin_src yaml :tangle (expand-file-name ".config/ansible/requirements.eg.yml" ansible-prefix)
---
collections:

  # basic
  - name: community.general
  - name: ansible.posix
  - name: ansible.netcommon
  - name: ansible.utils

  # you really don't want to overlook this one...
  - name: fedora.linux_system_roles

  # container/vm
  - name: kubernetes.core
  - name: containers.podman
  - name: community.grafana
  - name: community.libvirt

  # networking
  - name: cisco.ios
  - name: pfsensible.core
  - name: ansibleguy.opnsense

  # security
  - name: community.hashi_vault
  - name: community.crypto
  - name: devsec.hardening

roles:
  # manage subuid/subgid for users
  - name: rwxd.subuid_subgid
    version: v1.0.4
    src: git@github.com:rwxd/ansible-role-subuid_subgid.git
    scm: git
#+end_src

Other collections

+ awx.awx
+ openvswitch.openvswitch
+ lvrfrc87.git_acp

**** TODO potentially refactor to meta/requirements.yml and meta

*** Ansible Vault

*** AWX

** Playbooks

Hmmmm... thanks [[https://bruxy.regnet.cz/web/linux/EN/bash-cheat-sheet/][Bash Cheatsheet]]. Noam Chomsky gently weeps colorlessly for
Tarzan-child of wilderness (reference to alienation)

#+begin_src sh :var prefix=ansible-prefix
unset $dryrun
#prefix=
#dryrun=echo
#dryrun=
centos=$prefix/roles/centos
gcloud=$prefix/roles/gcloud
virt=$prefix/roles/virt
qemu=$prefix/roles/qemu

role_dirs="tasks,handlers,templates,files,vars,defaults"
dircmd=${dryrun-"mkdir -p"}
filecmd=${dryrun-"touch"}

if [ -e $prefix ]; then
    echo "creating template at $prefix"
    $filecmd $prefix/{homelab,cloud,virt,qemu}

    # make root directory
    $dircmd $prefix/{group_vars,host_vars}
    $dircmd $prefix/{library,module_utils,filter_plugins,tasks}

    # make role directories
    $dircmd {$centos/,$gcloud/,$virt/,$qemu/}{tasks,handlers}
    $dircmd {$centos/,$gcloud/,$virt/,$qemu/}{templates,files,vars,defaults}
    $dircmd {$centos/,$gcloud/,$virt/,$qemu/}{meta,library,module_utils,lookup_plugins}

    # this also works
    # $filecmd {$centos/,$gcloud/,$virt/,$qemu/}{tasks,handlers}/main.yml
else
    echo "set prefix"
fi

#+end_src

#+RESULTS:
: creating template at /mnt/secrets/test

I'm sure there's a better way to do this, but i've looked. In the various
attempts at learning ansible, I've way too much time looking for templating
tools that were not ad-hoc github collections

**** PFSensible Ports Playbook

I couldn't really get the =pfsensible= lookup plugin to work -- too many parsing
issues. So I gave up. However, the aggregate tasks still work.

This is a fairly standalone playbook, which is difficult to come by for PFSense,
though it would need to be run before other pfsense plugins. This is really the
difficulty in managing PFSense XML: there are logical dependencies between the
names used in firewall rules.

Some of the protocols lack IP protocol number specifications -- for GRE, for
example. Here's the key for the protocol names:

+ p_ :: tcp/udp (or non-specified)
+ t_ :: tcp
+ u_ :: udp

#+begin_src yaml
---
- hosts: pfsense
  gather_facts: true
  connection: ssh

  tasks:
    - name: "setup port aliases"
      pfsensible.core.pfsense_aggregate:
        aggregated_aliases:
          - { name: p_dns, type: port, address: 53, state: present }
          - { name: t_ssh, type: port, address: 22, state: present }
          - { name: u_ntp, type: port, address: 123, state: present }
          - { name: u_ipsec, type: port, address: 500 4500, state: present }
          - { name: p_awx, type: port, address: 9191, state: present }
          - { name: p_cockpit, type: port, address: 9090, state: present }
          - { name: p_prox_coro, type: port, address: 5404-5405, state: present }
          - { name: p_prox_web, type: port, address: 8006, state: present }
          - { name: p_synct_gui, type: port, address: 8384, state: present }
          - { name: t_synct, type: port, address: 22000, state: present }
          - { name: u_synct, type: port, address: 21027, state: present }
          - { name: u_dchpv6, type: port, address: 546-547, state: present, descr: "DHCPv6 546-547 (UDP)" }
          - { name: p_gnunet, type: port, address: 2086 1080, state: present, descr: "GNUnet" }
          - { name: p_https, type: port, address: 443, state: present }
          - { name: p_http, type: port, address: 80, state: present }
          - { name: t_hkps, type: port, address: 11371, state: present }
          - { name: t_imap, type: port, address: 143, state: present }
          - { name: t_imaps, type: port, address: 993, state: present }
          - { name: t_irc, type: port, address: 6667, state: present }
          - { name: t_irc_all, type: port, address: 6660-6669 7000, state: present }
          - { name: u_mdns, type: port, address: 5353, state: present }
          - { name: t_ldap, type: port, address: 389, state: present }
          - { name: t_ldaps, type: port, address: 636, state: present }
          - { name: t_smtp, type: port, address: 25, state: present }
          - { name: t_smtps, type: port, address: 465, state: present }
          - { name: t_smtps_sub, type: port, address: 587, state: present }
          - { name: t_nntp, type: port, address: 119, state: present }
          - { name: t_nntps, type: port, address: 563, state: present }
          - { name: u_openvpn, type: port, address: 1194, state: present }
          - { name: t_pop3, type: port, address: 110, state: present }
          - { name: t_pop3s, type: port, address: 993, state: present }
          - { name: t_postgres, type: port, address: 5432, state: present }
          # PPTP also uses IP protocol 47 (GRE)
          - { name: t_pptp, type: port, address: 1723, state: present }
          - { name: t_rdp, type: port, address: 3389, state: present }
          - { name: t_rsync, type: port, address: 873, state: present }
          - { name: u_snmp, type: port, address: 161-162, state: present }
          - { name: t_snmp, type: port, address: 161, state: present }
          - { name: t_squid, type: port, address: 3128, state: present }
          - { name: p_syslog, type: port, address: 514, state: present }
          - { name: u_tftp, type: port, address: 69, state: present }
          - { name: u_traceroute, type: port, address: 33434-33524, state: present }
          - { name: t_vnc, type: port, address: 5900-5999, state: present }
          - { name: t_vncl, type: port, address: 5500, state: present }
          - { name: t_bgp, type: port, address: 179, state: present }
          - { name: t_ceph, type: port, address: 6789 3300 6800-7300, state: present }
          - { name: t_ceph_extra, type: port, address: 6800-7300, state: present }


    - name: "setup mirrors aliases"
      pfsensible.core.pfsense_aggregate:
        aggregated_aliases:
          - name: mirrors_debian
            state: present
            type: host
            address: ftp.us.debian.org security.debian.org enterprise.proxmox.com downloads.proxmox.com mirror.cogentco.com debian.uchicago.edu mirror.keystealth.org mirror-new.csail.mit.edu debian.gtisc.gatech.edu mirror.us.oneandone.net
          - name: mirrors_fedora
            state: present
            type: host
            address: fedoraproject.org centos.org mirrors.centos.org mirror.centos.org mirror.stream.centos.org download.cf.centos.org dl.fedoraproject.org registry.fedoraproject.org
          - name: mirrors_guix
            state: present
            type: host
            address: ci.guix.gnu.org git.savannah.gnu.org bordeaux.guix.gnu.org
          - name: mirrors_nonguix
            state: present
            type: host
            address: substitutes.nonguix.org
          - name: mirrors_proxmox
            state: present
            type: host
            address: download.proxmox.com
          - name: hkps_keyservers
            state: present
            type: host
            address: keys.openpgp.org hpks.pool.sks-keyservers.net pgp.ocf.berkely.net
          - name: reg_fedora
            state: present
            type: host
            address: registry.fedoraproject.org registry.centos.org
          - name: reg_docker
            state: present
            type: host
            address: docker.io auth.docker.io registry-1.docker.io index.docker.io production.cloudflare.docker.io
          # #!$#@!%@!B %!@#$%
          - name: git_github
            state: present
            type: host
            address: github.com
          - name: dns_adguard
            state: present
            type: host
            address: 94.140.14.14 94.140.15.15 2a10:50c0::bad1:ff 2a10:50c0::bad2:ff
          - name: ca_verisign
            state: present
            type: host
            address: nstld.verisign-grs.com a.root-servers.net
#+end_src

** Facts

*** Printing Available Facts

This allows you to print out facts, but there's usually too many to be useful

#+begin_src yaml
---
- hosts: hostgroup
  tasks:
    - name: print firewall facts
      ansible.builtin.debug:
        var: ansible_facts
#+end_src

You could instead invoke the setup module directly and filter what's returned
([[https://www.educba.com/ansible-facts][source]])

#+begin_src sh
ansible hostpattern -e@myvault.yml --ask-vault-password -m setup -a "filter=ansible_mounts"
#+end_src

You can also invoke =.*_info= modules directly to extract existing configuration.

#+begin_src src
ansible centos --ask-vault-password -e@vault.yml -b -m ansible.posix.firewalld_info
#+end_src

*** Facts for Linux System Roles

There are two facts modules for =fedora.linux_system_roles=, below =$lsr_module=

+ fedora.linux_system_roles.firewall_lib_facts
+ fedora.linux_system_roles.selinux_modules_facts

The command below will output them.

+ Use =-bK= if you need to supply the become password.
+ You can't pass =-a "firewall: { detailed: yes }"= or any module arguments

#+begin_src sh
ansible -i $inventory_file -m $lsr_module -b $host
#+end_src

*** Transform STDOUT to YAML

Add =community.general= to your =requirements.yml= and download it from Ansible
Galaxy. Then specify it in your =ansible.cfg=.

#+begin_src conf
[defaults]
# either yaml or community.general.yaml should work
stdout_callback=yaml

# for ad-hoc commands using the `ansible` command
bin_ansible_callbacks=True
#+end_src

The following environment variables accomplish the same.

+ ANSIBLE_STDOUT_CALLBACK :: yaml
+ ANSIBLE_LOAD_CALLBACK_PLUGINS :: True

This is supposed to work, but doesn't produce any output for me using =ansible=

#+begin_src
ansible-command ... | sed -e 's/.*SUCCESS.*/}/g' | yq -y
#+end_src

Of course, that only works for a single host at a time.

*** Transforming Facts to YAML

Fortunately, ansible provides a few ways to do this, though there doesn't appear
to be a command-line option for it. You can use =register= in your playbook
config for extracting info into playbooks generally, which is indeed more useful
than =jq= and =yq= in most situations.

**** TODO fix this playbook

This doesn't really work, though it's unclear why.

#+begin_src yaml
---
- hosts: centos
  become: yes
  tasks:
    - name: Extract firewalld info
      register: fwresult
      ansible.posix.firewalld_info:
        # how do i specify no arguments to this module?
        # ansible centos --ask-vault-password -b \
        #  -e@vault.yml -m ansible.posix.firewalld_info
        zones:
          - public
    - name: I've tried defining the local_action in multiple scopes
      local_action:
        copy:
        content: "{{ fwresult | to_yaml }}"x
        dest: /tmp/firewalld_info.yml
#+end_src

**** Using =yq= to transform output

To transform =firewalld_info= results into yaml, you could also use =jq= and
=yq=. Both are straight python libraries, which is much better than having node
dependencies... which unfortunately, my system makes a bit difficult to work
with, since tools like =nvm= and =pyenv= expect =lib64= to link right on the
system (I still haven't had enough time to figure this out).

#+begin_src sh
ansible centos --ask-vault-password -e@vault.yml -b -m ansible.posix.firewalld_info > /tmp/firewalld_info.json
#+end_src

Yes, I need to get in there and clean up the YAML. The command =yq . -y= is how
you get =jq= to do absolutely nothing with the output.

#+begin_src sh
# this feels wrong
cat /tmp/firewalld_info.json | yq -y . > /tmp/firewalld.yml
#+end_src



*** TODO ansible facts metadata

This can easily contain sensitive data, so you should be aware of where these
files/logs get generated on your system. If you do not fully understand the
=ansible.cfg=, then the default settings will leave these laying around AFAIK.

When using =ansible -m $module= directly, particularly with info modules or when
gathering facts, the =--tree= option outputs to a specific directory.

* Ansible on Guix

Python will need to be installed separately (which is good)

|--------------+---------+----------------------------|
| package      | version | desc                       |
|--------------+---------+----------------------------|
| ansible      |   7.4.0 | provides ansible-community |
| ansible-core |  2.14.4 | provides ansible-core      |
|--------------+---------+----------------------------|

** Build a relocatable guix profile:

I would generally recommend against going through this, since =guix shell=
basically gains the same benefits. So I removed the loading from the =init-ansible.sh= script

However, it does provide a portable Ansible with consistent dependencies and
controllable environment. It's a generally interesting facet of Guix. I guess
other package archives could basically install to an arbitrary path, but this
generally needs to be provided ahead of time, unless stowed somewhere.

+ --system aarch64-linux :: makes the manifest portable to arm64
+ --relocatable :: twice enables binaries requiring user
  namespaces to function with a fallback execution engine
  - you may want the -RR relocatable option
+ -S :: creates links from the profile within the tar to the
  dependences in the guix packages

#+begin_src sh :eval no
guixpkg=$(guix pack --relocatable --system=x86_64-linux --compression=gzip --save-provenance \
      -L $HOME/.dotfiles/ellipsis \
      -m $SECRETS_HOME/.config/guix/manifests/ansible-usb.scm \
      -S bin=bin)
if [ ! -e $SECRETS_HOME/pkg ]; then
    mkdir -p $SECRETS_HOME/pkg
fi
cp $guixpkg $SECRETS_HOME/pkg
#+end_src

The package is built to =/gnu/store= and is in =$guixpkg=. Now unpack:

#+begin_src sh :eval no
tar -C $SECRETS_HOME/pkg -xzvf $guixpkg
#+end_src

The profile will be in =./gnu/store/*profile=. If there are multiple profiles
found in =$SECRETS_HOME=, then searching the =.tar= is a better way to find the
profile.

#+begin_src sh :eval no
guixprofile=$(tar --list -zf $guixpkg | grep 'profile/bin' | cut -d/ -f4)
ln -s $SECRETS_HOME/pkg/gnu/store/$guixprofile $SECRETS_HOME/.guix-ansible
#+end_src

After unpacking, the guix profile can be found more exactly with:

#+begin_src sh :eval no :tangle no
guixprofile=$(find $SECRETS_HOME/pkg/gnu/store -name "*-profile" -type d)
#+end_src

Then source the =$guixprofile/etc/profile= from a script. Some dependencies may
require symlinking =-S lib=lib= or =-S libexec/libexec=.

Test the profile's binaries in a clean shell with:

#+begin_src sh :eval no
guix shell --profile=.guix-ansible -- bash
#+end_src
