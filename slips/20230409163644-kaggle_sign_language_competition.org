:PROPERTIES:
:ID:       d346491a-2fe8-457e-8716-6474ba430085
:END:
#+title: Kaggle: Sign Language Competition

* Roam
+ [[id:03684d61-2d11-4ad8-99b5-0139ddda433c][Kaggle]]

* Summary

As much as I'd like to win, it's not in cards. It would be better to make things
more competitive, though I'm invisible anyways.

Depending on the mediapipe data, there is really no reason why all the top
competitors are getting 75% percent. The competitions should result in a
breakthrough, although an app to teach sign language may be worth the
investment.

** Objective

* Resources

** Data


*** Format

[[https://www.kaggle.com/competitions/asl-signs/data][Data Fields]]

Data Instances:

#+begin_example json

#+end_example


**** MediaPipe

*** External

** ASL
+ First [[https://www.handspeak.com/word/most-used/][300]] words

*** Video


+ [[https://youtu.be/ianCxd71xIo][100 Basic Signs]]

*** Journals

+ [[https://doi.org/10.1145/3519391.3519396][Understanding Challenges and Opportunities of Technology-Supported Sign
  Language Learning]]

*** Articles

* Notes

** ASL

*** Mechanics (Anatomic)

*** Intentionality

*** Prosody

*** Presentation (signals/channels)

*** Linguistics

**** ASL [[https://www.kaggle.com/competitions/asl-signs/data][Classifier Constructions]]

**** Morphology

**** Handsigns
***** Ambiguous Signs
From [[https://linguistics.stackexchange.com/questions/1621/do-sign-languages-have-ambiguities][S/O post]]
  - [[https://www.youtube.com/watch?v=qj1MQhXfVJg][ASL ABC Story]]

**** Clustering

***** Verbal Languages

For verbal languages, it's important to articulate distinguishing
characteristics of ambiguous phoneme sequences that are composed of
grammatically/contextually conjugated morphemes. The potentially ambiguous
sounds or meanings form clusters. Native speakers articulate these differences
instinctively and usually subconsciously. This need drives the development of
accents, vocabulary selection, slang/cryptolect formation and language
evolution. For these clustered phoneme sequences, opposite dynamics can result
in tendencies to select phrasings/voicings that sound similar by choosing
synonyms or making slang.

Mutation, selection and recombination are three dynamics studied in population
genetics which are applicable metaphors here. The distance between clusters or
between sequences in the same cluster -- i.e. the need to be understood by all
parties or not understood by some parties -- drives these three dynamics in
linguistic evolution.

[[https://doi.org/10.1007/978-3-319-52045-2][Information Geometry and Population Genetics]] ... or Reimannian Geometry with
less Einstein

***** Sign Languages

Similar dynamics occur, resulting in a simlar response among those who sign,
though the physicality, the sensory modality and the potentially restricted
vocabulary in inexperienced ASL speakers have much larger effect on how people
seek clarity.

Still, the need to articulate signs for expression or for clarity should be an
identifiable feature/proxy, if for nothing else than for uncertainty and to
prioritize compute..

#+begin_quote
... I really don't know what I'm talking about, which I think I should probably
re/iterate. In case I've gotten something wrong or worse.

My interest in ASL has been driven by curiosity in linguistics, the neurological
implications of using an entirely different set of circuits in the brain to
process language ... and potential cognitive benefits of doing so. This is a bit
selfish, so I'm sorry about that. I've never made much progress towards ASL.
#+end_quote



** Data

*** Artifacts

+ Segues & transitions: if the signs are outtakes from more complete statements,
  then the hands will need to transition to the necessary positions, affecting
  the presentation and creating cases that are tough to classify.

*** Errors

*** Leakage

+ repeated sequences of signs

**** Hidden Proxies

+ Zipf-like Distribution (adjusted for the 250 signs) ... though the bias here
  will likely not appear in the labeling, it will appear in how the ASL speakers
  have engrained the signs.

*** Cleaning

*** Processing

* Issues

** Compute Requirements



* Ideas
** Quantify Uncertainty

** Quantify Intentionality

Dimensional analysis on fingers/joints (req. labeling segments)

+ Not all motion is equally likely & some motion is impossible
+ Not all motion is useful for expression
+ Some subset of what's not moving may be as important as what is moving
+ A person's visual field is a fairly narrow cone
  - the direction of visual focus can be quantified in terms of steradians
    (angle) and min/max depth.
    - the exact calcuations are not useful (and can't be validated)
    - but the implication is that ASL speech should move towards the chest or
      around the face when the speaker wants the listener to tune into the
      facial cues (or really that when the signing moves away from these
      regions, it would be hard to convey the speech without distance between
      the speaker/listener)
  - perhaps useful when deciding whether to use facial features for inference

** Use Physical Energy

** Parameter Extraction
+ points of rotation

* Tasks


* Phases

1) setup environment (python, data, project)
2) test basic assertions about data
3) find mediapipe tools and other libraries
4) look for external data sources
5) write some shitty models
