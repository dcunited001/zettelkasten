:PROPERTIES:
:ID:       4ea74826-8caf-47d0-bb40-f23e27359d07
:END:
#+TITLE: Cloud: Terraform On GCP
#+CATEGORY: slips
#+TAGS:

* Docs

* Resources

* Notes

** Pricing

*** Tiers

+ TF Enterprise is basically equivalent to the TF Cloud Business Tier

|                      | TF Open Source            | TF Cloud | TF Enterprise |
|----------------------+---------------------------+----------+---------------|
| License/Cost         | none                      | 3 tiers  | $$$$          |
| Managed              | No                        | Yes      | Money Talks   |
| Hosting              | Local Machine or Cloud VM | SaaS     | On-Prem       |
| Concurrent Deploys   | No                        | Yes      | Yes           |
| GUI                  | CLI Only                  | Yes      | Yes           |
| Operational Overhead | The sky is the limit      | Light    | Heavy         |



** Concepts

+ Manage infrastructure
+ Track changes
+ Automate changes
+ Standardize configurations

*** Provisioning vs Configuration

The concepts are blurred and aren't simple to discriminate. In networking
contexts, whether signaling to routers or GCP network device objects,
provisioning may include sending a subset of network state sufficient to
complete the configuration. Sometimes, you may consider this configuration
management, but the two are not separated from each other in semantics or in
your processes/code. This convolutes your projects and processes.

+ Provisioning :: signaling to VM hosts, cloud API's, network controllers or
  rack controllers to manage objects.

  In the cloud, the API provides an interface with rules/logic. You signal to it
  and on the backend it prepares the cloud provider state. You receive signals
  from it in response and proceed with provisioning. On bare metal, this would
  involve some cfg mgmt.

+ Config management :: distributing configuration/state to entities on the
  network, usually internal to those entities. e.g. cloud-config or ssh keys or
  network device configuration.

*** Stages/Commands

| write   |   |
| init    |   |
| plan    |   |
| apply   |   |
| destroy |   |

**** init

Basically downloads modules and preps the TF environment.

**** plan

The TF plan output is a diff & can be saved for input to later TF commands.

+ Use =-out= to save and =terraform show -json $file= to convert to json. Use
  =jq= FTW. The JSON Format is [[https://developer.hashicorp.com/terraform/internals/json-format][here]].
+ The plan instructions are sorted according to resource identifiers

**** validate

Run some checks. Helps ensure adherence compliance.

+ Encorce policies
+ Remove manual errors
+ Reduce time to learn

TF doesn't have a great "undo" shortcut. Sometimes it's easy other times it's
not. This is true of automation generally and other frameworks. You'd really
want to know before you do something -- especially if it's a mistake that is not
made abundantly obvious by =terraform apply= output.

Reasonable assumption of responsibilities (as long as you don't have the fool
stack position)

| Platform teams    | guardrails on the CI/CD pipelines. collab on central policy    |
| Application teams | validate TF config with central policy library                 |
| Security teams    | create org/project's central policy lib and prevent violations |

**** apply

This gives you a chance to review/modify values (before running apply) or to
abort. Terraform apply will try to destroy resources according to the
constraints imposed by the provider's backend (the plan should

+ The =terraform destroy= command is an alias for =terraform apply -destroy=
+ The =-state= and =-state-out= options allow you to control input/output
+ State locking with =-lock= ... interesting
+ Control threads/tasks with =-parallelism=

  | option       | default           |
  |--------------+-------------------|
  | -state       | terraform.tfstate |
  | -state-out   | -state            |
  | -backup      | -state-out        |
  | -parallelism | 10                |

**** fmt

Don't commit shit. Lint your codes. What is this a blog?

** Workflow

*** Running Terraform

+ TF itself doesn't require authentication, only the provider.
+ TF on Cloud Shell: preauthenticated, but still needs roles assigned to do
  anything useful.
+ TF on a workstation: requires =gcloud auth application-default= to authenticate
+ TF on a VM: configure Google Service Accounts
+ TF outside GCP: use workload identiy fedration, generate short-lived SA key
  and set env variables. SA key rotation not allowed.

**** GCP Terraform Validator

In addition to =terraform validate= which ends up running =gcloud beta terraform
vet=. The same structure/types of constraints specifed for =terraform validate=
for that the GCP provider implements should also extend to other providers.

*** Cloud Share

** Ecosystem

*** TF Registry

A package manage repository for TF modules

*** Cloud Foundation Toolkit (CFT)

+ Blueprints for architecture patterns in GCP.
+ CFT supplies example modules building on modules in the standard GCP provider

For example, compare an implementation using CFT =projects_iam= to the standard
TF =google_project_iam_binding=. Here, the CFT module allows you to maintain the
IAM roles for multiple projects within the same module, whereas the GCP provider
requires that you loop over each project, role and binding

NOTE: is it possible to loop over resource declarations?

** Projects

*** Providers

*** Inputs/Outputs

+ Define inputs/outputs and most logic in =main.tf=. Outputs connect modules to
  subsequent modules (visualize a modular synth with patch cables)
+ Define variables in =vars.tf=. Change variable values for various deployment
  environments in file =terraform.tfvars=, but these should wind up in Git (esp
  for gitops)

**** Outputs

+ Attributes include: value, description, sensitive
+ Use =terraform output= to view output values used in a project.
+ Use outputs where possible, esp. when they are deterministically generated
  values. They avoid the need for subsequent =.tfvars= in downstream modules,
  reducing the configuration surface area.

***** Best Practices

+ Avoid outputs that simply regurgitate variables or provide known information
+ Inputs/Outputs should facilitate modularity, but too many may increase
  cognitive overhead when working in projects that combine many TF
  modules.

e.g. can you determine that for all relevant (recent) versions and for projects,
that removing a module input/output won't break the build somewhere for someone?

Only output useful information, e.g.

+ =fdsa.vpc-network.id=, not =fdsa.vpc-network.name=
+ default_gateway_ip4
+ id :: the ID of a resource
+ self_link :: the URI of a resource

*** Variables

+ TF infers types for variables. This is dep. on types in the provider's modules
+ Specify =description= to affect documentation & CLI output
+ Specify =sensitive= to avoid having vars in logs/output
+ Use =default= where it makes sense.
+ Terraform automatically includes vars defined in terraform.tfvars[.json],
  terraform.tfvars and .auto.tfvars[.json]
+ the variable values can be provided by multiple methods, but =-var= has the
  highest precedence.

Options for supplying values to vars:

| type        | purpose                                                                       |
|-------------+-------------------------------------------------------------------------------|
| .tfvars     | switching between sets of variables and versioning them                       |
| CLI options | useful when running quick examples on simple files (doesn't jive with gitops) |
| Env Vars    | useful in scripts/pipelines                                                   |
| CLI prompt  |                                                                               |

**** Best Practices

+ Prefer specifying variable defaults in module definitions followed by
  =.tfvars= files over using CLI =-var= options
+ Add units to variable descriptions AND names (these aren't necessarily
  standard across cloud API's)
+ Prefer positive names for boolean variables

***** When to add/remove variables

Changing a var where a default value is supplied is backwards-compatible;
removing a variable is not. Thus, only parameterize values that must vary for
each instance/environment.

Preemptively adding variable values that are later removed creates situations
that require checking out alternate versions of code (and potentially patching)
in order to:

+ apply a previous version's plan with specified/modified TF state.
+ applying a current version's plan with previous TF state (usually missing
  variable values would be prompted)

This is a bigger problem when many projects/environments share common TF
modules. When many devs/teams share these modules, adding/removing variables can
require version pinning, which may slow progress across teams. Having
rules/logic in place to determine how/when to add variables avoids some simple
situations that complicate version management in shared module dependencies.

****** TODO review implications of adding/removing variables in TF modules



** Resources

*** Meta-arguments

+ count: create a set of n resourcese.g: =${count.index + 1}=
+ for_each: expose an index for looping, e.g. =toset(['us-east1', 'us-east2'])=
  and =${each.value}=
+ depends_on: specify explicit dependencies (ordering of creation in =apply=)
+ lifecycle: handle creation/deletion or other lifecycle parameters
+ provider: specify alternate defaults for the provider configuration

*** Resource Dependencies

View a dependency graph with =terraform graph | dot -Tsvg > graph.svg=

+ Can be specified out of order (TF HCL is declarative)
+ View ordering of implicit deps via =terraform apply=

* Roam
+ [[id:8a6898ca-2c09-47aa-9a34-a74a78f6f823][Cloud]]
+ [[id:ac2a1ae4-a695-4226-91f0-8386dc4d9b07][DevOps]]
