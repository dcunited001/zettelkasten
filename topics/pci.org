:PROPERTIES:
:ID:       7042ca6c-cd4a-4f7a-8c25-114c321b8cf9
:END:
#+TITLE: PCI


* Docs

* Resources

* SR-IOV

* IOMMU

* Topics

** Bios

*** Modification

**** [[https://tachytelic.net/2021/12/dell-optiplex-7020-nvme-ssd/][Support NVMe on Dell 9020 by Modifying BIOS]]

Don't ... but still interesting.

The article guides you through using Intel Management Engine to do unspeakable
things using software intended to run on an unnamable operating system

** Bus (general)

*** Links
+ [[wikipedia:bus_encoding][Bus Encoding]]
+ [[https://en.wikipedia.org/wiki/Differential_signalling][Differential Signaling]]
+ PCIe

*** Ideas
  
In case of ""CUDA for RAM read/write""... viz.

For any non-prime 1D array A of size M, it can be broken into an N-dimensional
rectangular array whose N dimensions are defined by the factors of M. For the
potential "factor-trees" of any integer, the sum any possible arrangement of
factors is least when it is fully reduced entirely to prime factors (bc
multiplication big, addition small according to Ug). Array A can be rolled into
many permutations of n-dimensional arrays where n < N.

e.g. a 1D array can become a 2D array, indexed by stride (and offset). If the
array factors, it can become a 3D array with further stride parameters.

This is useful for random number generation: in 1D, all elements have 2
neighbors; in 2D, 4 neighbors (up,down,left,right); in 3D, 6 neighbors; etc. You
can take a fairly random matrix and produce another without biased diffusion of
bits. See this example that I wrote... [[since ][A Terrible GPU PRNG with WebGL]]. Of
course, the numbers generated are all correlated. The simulation includes an
animation of the entropy (but not the change in entropy).

It is potentially useful for increasing the speed of RAM read/write, provided a
bus topology with multiplexing or channels. A serial bus is a bottleneck, but if
you can push/pull data to/from RAM in parallel (without a time penalty like with
AGP cards), then you can move data between devices faster. Further, you can also
specify reads/writes for matrices using the [inconvenient and impractical]
N-dimensional array described above.

I can't imagine that this RAM idea would ever be practical, since ... yeh. It's
not. Take the world population of CUDA programmers and divide by one million.
Now add a few new architectures to C compilers and divide by whatever custom
silicon you need. And your answer is the number of customers.

As for the CUDA-like aspect: to apply this, you need to make calls to the
hardware from C with a language that tells you how to read/write the array
elements (or otherwise operate on them). "CUDA" mostly refers here to the
difficulty and impracticality. Quite a few matrices I know are at least square
though.

**** A CUDA-like API for Compute-In-Memory

Apparently, this idea will be useful, though not to the average plebian:

+ [[https://www.youtube.com/watch?v=5tmGKTNW8DQ][AIâ€™s Hardware Problem]] (asianometry youtube)
+ Since there are so many ways in which you can approach this memory-bottleneck
  problem, (and since the potential payoffs are application-specific where each
  application requires specific archetectures), then even prototyping this
  requires a generalization of the "virtual machine" concept beyond simple Von
  Neumann machines.
  - that is, you would virtualize the bus architecture and memory/compute
    devices to include bus-archectures with the potential for feedback loops and
    tiered memory caches in multiple hardware elements.
    - i.e. your compute-in-ram elements would have a tiered cache with n-cycle
      time-delays for computing cache results (matrix multiplications) and
      n-cycle cache-expiry -- together with perhaps a secondary bus for
      managing/ingesting data from compute-in-ram cache to main CPU.

** Storage

*** Issues

**** Determine whether SATA Hotplugging is enabled without checking BIOS

+ Some details in this [[https://forum.manjaro.org/t/solved-how-do-i-enable-sata-hotplug/2911/7][manjaro post]].

Install sg3_utils and scsiadd
