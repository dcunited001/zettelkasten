:PROPERTIES:
:ID:       a0ef7bfe-1587-4fec-ac87-f7dda5dc0d20
:END:
#+TITLE: Maths: Algebra
#+DESCRIPTION: The Shapes of Clouds and Stuff
#+TAGS:

* Roam

+ [[id:a24b12f8-b3e3-4f66-9a5c-f29b715e1506][Math]]

* Docs

+ [[wikipedia:Algebra][wikipedia:Algebra]]

* Linear Algebra

** Resources

+ [[http://www.cs.cornell.edu/~tomf/notes/cs421-cheat-sheet.pdf][CS 421 Cheatsheet (Thomas Finley)]]

** Determinant

The determinant is profound

*** Minors and Cofactors


* Tensor Algebra

** Factorization

+ [[https://www.tcrwebsite.org/volumes/1700003/la/v4_pdf/LA-04][Deconstructing Hedonic Experiences Using Tensor Factorization]] (not even a
  joke)

*** De Lathauwer

These have a good level of detail and nice/concise summaries.

**** arXiv: 1607.01668

[[https://arxiv.org/abs/1607.01668][Tensor Decomposition for Signal Processing and Machine Learning]]

**** arXiv: 1403.4462

[[https://arXiv.org/abs/1403.4462][Tensor DecompositionS for Signal Processing Applications]]

From Two-way to Multiway Component Analysis


** With Discrete

*** With Trees

**** TODO Noter: [[https://arxiv.org/abs/1703.10252][Linguistic Matrix Theory]]

+ arXiv: 1703.10252
+ Interesting approach to linguistic data: "Physicists do ML; hold their beers."

#+begin_quote
I found this /while trying to stay positive/semidefinite/ looking for examples
of random matrices, maybe specifying tensors -- that was a joke btw: can I just
nudge non-invertable matrices until i get one that fits a set? does the
statistical mechanics mulligan apply? probably not. i'm thinking "matrices with
norm 1" and add in some representation theory
#+end_quote

***** TODO Noter: [[https://arXiv.org/abs/2202.06829v2][Permutation invariant matrix statistics and computational language tasks]]

+ arXiv: 2202.06829v2 (shares two authors with Linguistic Matrix Theory)

**** TODO Noter: [[doi:10.4230/LIPIcs.FSTTCS.2019.44][The Tree-Generative Capacity of Combinatorial Categorial Grammars]] :noter:

doi: 10.4230/LIPIcs.FSTTCS.2019.44

+ CCG's are used to model grammar.
+ alphabet is a finite set of symbols


+ There aren't tensors here. It would be good to learn how/where such a
  structure (similar to Linguistic Ran

*** With Networks

**** TODO Noter: [[doi:10.1109/TNSE.2015.2419133][Algorithmic Renormalization for Network Dynamics]]

doi: 10.1109/TNSE.2015.2419133

+ Describes rules for a HK system (Hegselmann-Krause), then generalizes the
  relations between agents using the $\Phi_{i,j}$. This is effectively a
  function for each =i,j= which returns the adjacency matrix for agents in the
  simulation.
+ the example with robotics & delauney triangulation doesn't prove that a
  first-order theory of reals is necessary to bundle into $\Phi_{i,j}$ many
  logical statements about =HK-system=
+ the system(s) on p3 were impractical (the complexity is the challenge here).

but it does get interesting on p4, as it combines elements from:

+ physics: p4+ phase-space. also, to renormalize and rescale requires some
  attempt at a conservation of measure, even for these systems
+ chaos theory & equilibrium (or lack thereof)
+ hyperbolic geometry grounded in a shared "unit cube" that also must
  necessarily provide paths for traversal where agents may be connected.
+ functions and sequences on the graph (using the graph as domain)
+ again, the letter/alphabet, word, sentence abstractions make an appearance
+ mixed timescales: this shows up everywhere. nowhere do you have continuity if
  it runs on a computer.

  This reminds me of some of the WebGL social physics simulations that I wanted
  to build.


* References
