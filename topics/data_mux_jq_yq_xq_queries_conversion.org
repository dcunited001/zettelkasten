:PROPERTIES:
:ID:       cdf0de7c-cf7c-456f-a12c-b2496359064b
:END:
#+TITLE: Data Mux: JQ, YQ, XQ, Queries, Conversion
#+DESCRIPTION:
#+TAGS:


* JQ/YQ/XQ

** Docs

** Resources

*** Alternatives

+ [[https://github.com/sclevine/yj][sclevine/yj]] :: convert between json, toml, yaml, hcl

** Topics

*** Examples

**** Find examples of docker compose with services that have volumes

Or =tty= and etc...

#+begin_src shell :results output verbatim code :wrap example yaml
# regwhy='' # something something to filter out
regex='/data/ecto'
n=8 # unfortunately brittle
files=$(locate 'docker-compose.yml' | grep $regex | head -n$n)
yq -y '
.services | to_entries[] | select((.value | type == "object"))
| {svc: .key,
   volumes: .value.volumes}' ${files[@]}

# '| select((.value | type == "object"))
# | {svc: .key,
#    volumes: .value.volumes}' ${files[@]}
#+end_src

#+RESULTS:
#+begin_example yaml
svc: fastai
volumes:
  - .:/data/
---
svc: notebook
volumes:
  - .:/data/
---
svc: watcher
volumes:
  - .:/data/
---
svc: jekyll
volumes:
  - .:/data/
---
svc: web
volumes:
  - grafana-storage:/var/lib/grafana
---
svc: db_mongo
volumes:
  - grafana-mongo-db:/data/db
---
svc: elasticsearch
volumes: null
---
svc: logstash
volumes:
  - ./logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
  - ./logstash/nginx.log:/home/nginx.log
---
svc: kibana
volumes: null
---
svc: elasticsearch
volumes: null
---
svc: logstash
volumes:
  - ./logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
  - ./logstash/nginx.log:/home/nginx.log
---
svc: kibana
volumes: null
---
svc: elasticsearch
volumes: null
---
svc: logstash
volumes:
  - ./logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
  - ./logstash/nginx.log:/home/nginx.log
---
svc: kibana
volumes: null
---
svc: elasticsearch
volumes: null
---
svc: logstash
volumes:
  - ./logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
  - ./logstash/nginx.log:/home/nginx.log
---
svc: kibana
volumes: null
---
svc: elasticsearch
volumes: null
---
svc: logstash
volumes:
  - ./logstash/pipeline/logstash-nginx.config:/usr/share/logstash/pipeline/logstash-nginx.config
  - ./logstash/nginx.log:/home/nginx.log
---
svc: kibana
volumes: null
---
svc: fake-app
volumes: null
---
svc: zookeeper
volumes: null
---
svc: broker
volumes: null
---
svc: sensu-backend
volumes: null
---
svc: sensu-agent
volumes: null
---
svc: sensu-cli
volumes: null
---
svc: ansible-rulebook
volumes: null
#+end_example


*** Tree Traversal

**** Combining Multiple Queries

For projects/scripts that require many tree traversals and can make guarantees
on niceness/schema for tree structure, then it may be more useful:

+ tangle queries into separate files (or write them as such)
+ and use the =/bin/sh= pipe operate to pipeline modifications.

Compare these three queries

#+name: jqRemoveSVG
#+begin_example jq
walk(
  if type == "object" and has("svg") then
    .svg = {Icon: {"@type": "Icon"}}
  else .
end)
#+end_example

Slightly more complex, but less composable

#+begin_example jq
walk(if type=="object" then
  if has("svg") then {Icon: {"@type": "Icon"}} else . end
  # Additional queries here -- this is like an extra { block; } in awk
else
  .
end
#+end_example

Way more complicated.

#+name: jqWalkDom
#+begin_example jq
walk(if type == "object" then
      to_entries
        | map(. |= if .key == "svg" then {key: "Icon", value: {"@type": "Icon"}} else . end)
        | map(. += if .key == "@class" then {value: (.value | gsub("\\b\\sdark:[\\w\\-:]*\\b"; ""))} else . end)
        | from_entries
     else .
    end)
#+end_example

**** Generic

... and only then do i see =.what?= ???! GDMT (see giant any/all query)

#+name: jqHuh
#+begin_example jq
# .. | [ any(."@class"?) ]
# .. | map(any(."@class"?))

# swapping the order of $fdsa and the select breaks the query.
# - it also doesn't really retrieve what i want
.. as $fdsa | [ select(type=="object") | any(."@class"?), $fdsa ]

# this also works and is simple, but without order guarantees, it's useless

# [ paths | [ join("/") ]]
#+end_example

#+headers: :var jqHuh=jqHuh
#+begin_src sh :results output code :wrap src yaml
cat $_REPO/typescript/components/flowbite/components/accordion/accordion-always-open-example.html |\
    tidy -iq --tidy-mark no -w 0 --show-body-only auto --doctype omit -xml |\
    xq -y "${jqHuh}"
#+end_src

Trying to fanout the list of paths to apply to other functions is obnoxius
... but there is probably just the thing i don't know about ... which is the
obvious thing that handles the obvious use-case. But IDK it.

So since =paths($arg)= doesn't allow you to pipe to it, most of what i'm trying
to do does not work. it also would not be efficient ... but i wasn't going for
efficient.

***** Any/All

These can be woven (or interleaved) with the results of another method that
produces objects/paths -- like recurse, paths, etc. as it traverses the tree. As
long as the order is consistent, then you can apply the result =any= or =all=.

For example, this would help you remove all objects in a DOM tree that don't
specify class

#+name: jqWovenZip
#+begin_example jq
# .. | select(type=="object" and has("@class"))
# [.. | select(type=="object") | any(type=="object" and has("@class"))] | all

#. as $og
# | [ paths | [ join("/"), . ] ]

#paths
. as $orig
| [ $orig | paths,
# ....................
    recurse | getpath($orig) | any(type=="object" and has("@class"))]

# | map(any(type="object" and has("@class"))) ]


# getpath(paths)

# [ paths
# | map(. as $p | join("/")
# #  [ join("/")
#   #,. as $p | [ path($p)]
# #  ]
#   )]

  #| recurse | select(type=="object")
  #                 | any(type=="object" and has("@class"))] | all])]
#+end_example

#+headers: :var jqWovenZip=jqWovenZip jqRemoveSVG=jqRemoveSVG
#+begin_src sh :results output code :wrap src yaml
cat $_REPO/typescript/components/flowbite/components/accordion/accordion-always-open-example.html |\
    tidy -iq --tidy-mark no -w 0 --show-body-only auto --doctype omit -xml |\
    xq -y "${jqRemoveSVG}" |\
    yq -y "${jqWovenZip}"
#+end_src

#+RESULTS:
#+begin_src yaml
jq: error (at <stdin>:1): Cannot iterate over string ("accordion-...)
[ Babel evaluation exited with code 5 ]
#+end_src

***** Using =path(..)=

Any way to get this to work? Using =tree --json //sys= as data source?

#+begin_src sh
tree -L 2 \
     --prune --matchdirs \
     -P '[aeiou]*' /sys \
    | jq '. as $dot | path(..) as $p | map($dot[.])'
#+end_src

**** Walk

**** Recurse


*** XQ

**** Working with Attributes

Specifying =[]= after =.manifest.project[]= causes document separators to be
inserted for =xq -y= output. Annoying if you're not expecting, but useful
otherwise. The =[]= is somewhat of an implicit map.

While also relevant to =jq=, this is more helpful for =xq= to =yq= conversions.
The triple-dash document separators are actually part of the YAML standard
whereas =jq= must know to parse them while maintaining escaped strings.

This first query creates a unified stream where each XML node can be treated as
separate documents, whereas the latter splats everything together. They both
lose their identity as =<project/>= nodes.

#+begin_src sh :dir (identity dc/repo-path) :results output verbatim :wrap example yaml
xq  -y '
    .manifest.project[]
    | select(."@path" != ."@name")' typescript/astro-themes.xml
#+end_src

#+RESULTS:
#+begin_example yaml
'@name': abdllahdev/nimbus-narratives
'@path': algorizr/nimbus-narratives
'@groups': blog,preact,tailwind,typescript,mdx
---
'@name': bywhitepine/astro-minimal-starter
'@path': jaydanurwin/astro-minimal-starter
'@groups': minimal
---
'@name': bywhitepine/cannonball
'@path': littlesticks/cannonball
'@groups': landing-page
---
'@name': bywhitepine/odyssey-theme
'@path': littlesticks/odyssey-theme
'@groups': featured,landing-page
---
'@name': bywhitepine/simple-blog-astro
'@path': littlesticks/simple-blog-astro
'@groups': blog,lit,mdx
---
'@name': Johnkat-Mj/agency-landing-page-astrojs
'@path': Johnkat-Mj/agencex-astro
'@groups': landing-page,tailwind
---
'@name': LaB-CH3/astrobrew
'@path': anthonylan/astrobrew
'@groups': landing-page
#+end_example

Without separators:

#+begin_src sh :dir (identity dc/repo-path) :results output verbatim :wrap example yaml
xq  -y '
    .manifest.project
    | map(select(."@path" != ."@name"))' typescript/astro-themes.xml
#+end_src

#+RESULTS:
#+begin_example yaml
- '@name': abdllahdev/nimbus-narratives
  '@path': algorizr/nimbus-narratives
  '@groups': blog,preact,tailwind,typescript,mdx
- '@name': bywhitepine/astro-minimal-starter
  '@path': jaydanurwin/astro-minimal-starter
  '@groups': minimal
- '@name': bywhitepine/cannonball
  '@path': littlesticks/cannonball
  '@groups': landing-page
- '@name': bywhitepine/odyssey-theme
  '@path': littlesticks/odyssey-theme
  '@groups': featured,landing-page
- '@name': bywhitepine/simple-blog-astro
  '@path': littlesticks/simple-blog-astro
  '@groups': blog,lit,mdx
- '@name': Johnkat-Mj/agency-landing-page-astrojs
  '@path': Johnkat-Mj/agencex-astro
  '@groups': landing-page,tailwind
- '@name': LaB-CH3/astrobrew
  '@path': anthonylan/astrobrew
  '@groups': landing-page
#+end_example



** Issues

*** Workflow

**** Slow Down

The real issue I find that my workflow, whether =org-babel= or in KDE =konsole=,
is usually ad hoc. I just happen to find myself using it in a situation where
=awk/sed= are just overkill (viz. where data structure is well-defined)

+ I'm either half-in a bash shell or in an org-babel block.
+ Esp in bash, it's not plain to see how changes to the query correspond to the
  output -- or stack trace, which is /not/ colorized (and I swear I have
  dyslexia when some content lacks syntax coloring).
+ Worst of all, things like LSP doen't easily work in mixed-mode buffers like
  =org-mode= ... and emacs is single threaded[fn:1].

So learning =jq= has been slow. I encountered many similar problems with
=graphql=

***** Ways to alleviate the "workflowitis"

I don't slow down to ensure that the the environment is set up for quick
feedback loops. It's usually on some short wistful excusion (i.e. a
distraction), but one that's irritated me for so long already. Thus, I'm always
conflicted between "should already know this and & tired of it" and "I should
get back to what I was working on". I judge the time investment as being 10
minutes, but then never actually set up a quick environment so that tools are
efficient. Next thing I know, 45 minutes or 2 hours later...

****** Decide on a common process

If some single process worked, it would be to create a script that sets up a
temporary directory (or something) where you can place each stage into =*.json=
and =*.jq= files, where =inotifywait= runs tasks on demand.

This doesn't really work well, since it's just useful wherever you encounter
=json= or =yaml= and now =toml/xml= to some extent. This isn't easy because of
the subtleties of eliciting is from sources like:

+ The =tree= command's output of the =/proc= or =/sys= filetree
+ Or other commands like =loginctl=, the LVM CLI tools, =ip= tools
+ Some =curl=, particularly if the output structure is affected by query
  parameters or is for some other reason non-deterministic (or something)
+ Configuration in =yaml= or =toml= for the paths (or potential relative paths
  between them) for which can't be guaranteed to be retained across systems
+ Devops configs specifically. To ensure the sensitive data isn't
  unintentionally littered everywhere, these may require setting specific
  constraints or configs on environment (generally making determinations about
  how to ensure Future Self doesn't forget)
+ Yaml from something like =ansible=

It's not really clear that there is some single such tool to invoke =jq=

****** Break problem into pieces

Why not just send to tmp file? Or break process into pieces?

While this is usually simple enough, usually requires deciding where data will
live should I need to set it aside.

+ Org-mode usually helps these facilitate either deciding on these data points
  or avoiding the need to do so entirely
+ Bash is helpful, since you kinda want the data to be ephemeral (esp. if long).
+ It may already be half-processed and in some in-between state. And
  with each stage of transformation, it's not immediately clear that pulling the
  =jq= query bac into the rest of your pipeline will simply "just work."

*** Learning

**** Recommend the =jq= source!

The secret to learning =jq= without a Sith Master is, of course, is to purge
blogs/etc from the internet and reach for the source code first.

There have only been one or two resources which ever recommended looking at the
=jq= implementation in its own source code ... and none of them mentioned any
=*.jq= file. It's entire documentation is basically out-moded once you look at
the source.

**** Nuance, there's so much niched nuance =</ryan-reynolds>=

If I could just recall tree traversal quickly enough to adapt it to the
situation at hand, then =jq= would be pretty simple for almost every situation I
need it.


*** XQ not attributing

If you find your self with an =xq= that just can't meaningfully convert
documents to XML, just try converting a document from XML to YAML ... you'll
find that you need to use =@= to set attributes ... maybe idk. =xq --help= does
not mention this at all.

Like this:

#+begin_example sh
echo meooow |\
  awk -f concat-yaml.awk |\
  yq -sy . |\
  yq -sy '.[] | map(select(.repoUrl))' |\
  yq -x --xml-root WOW 'map({LIKE: .title, "@MUCH": "WTF"})'
#+end_example

Yeh wow, that would've helped quite a bit.

*** ob-jq in emacs

+ results :: use =output= to reuse strings in another babel block that doesn't
  parse json. this eliminates the quoting
+ cmd-line :: use =-r= for =--raw-output= and =-j= to eliminate the trailing
  newline.
+ stdin :: an org-babel reference
+ in-file :: a file reference

#+begin_example org
#+property: header-args:jq :stdin varname :cmd-line --raw-output

the above header args are for reference but would set defaults

#+name: ffactive
#+headers: :results output silent
#+begin_src jq :stdin ffprofilesjson :cmd-line "-rj"
. | your | query
  | here | @text

# or @tsv or @csv
#+end_src
#+end_example

** Examples


* Roam
+ [[id:c99b63b3-e18f-4b4b-8424-dbbac937b596][Serialization]]

* Footnotes

[fn:1] Not that multi-threaded ish would help much since an editor (regardless
of whether the treesitter language support is statically compiled, dynamically
loaded, or using the process model) ... though I guess it's possible for sockets
to manage the treesitter results. But then you would have serious
synchronization problems (regardless of whether multi-process or
multi-thread). Tree-sitter should be capable of reporting its results in a
fairly compact format (like maybe this [[https://web.archive.org/web/20220527003730/https://tools.ietf.org/doc/tcllib/html/rcs.html][RCS format]] mentioned by Apheleia). Still,
It would be interesting to see how Zed implements its tree-sitter functionality
