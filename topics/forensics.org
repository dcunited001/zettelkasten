:PROPERTIES:
:ID:       45b0ba21-fb20-44dc-9ee9-c4fed32aba9c
:END:
#+TITLE: Forensics
#+CATEGORY: topics
#+TAGS:

* Roam

+ [[id:29d8222b-618f-454e-8a76-6fa38f8ff1f6][Blue Team]]

* Digital Forensics
** Docs

*** SIFT

+ [[https://linuxleo.com/Docs/LinuxLeo-4.95.1.pdf][The Law Enforcement and Forensic Examiner's Introduction to Linux]]
+ Sans Institute [[https://www.sans.org/posters/?msc=main-nav][Posters & Cheatsheets]]

*** [[github:ForensicArtifacts/artifacts][ForensicArtifacts/artifacts]]

+ [[https://artifacts.readthedocs.io/en/latest/][Docs]] with [[https://artifacts.readthedocs.io/en/latest/sources/background/Stats.html#artifact-definition-source-types][Stats on Artifact Defs]] (OS, source type, etc)
+ [[https://artifacts.readthedocs.io/en/latest/sources/api/artifacts.html][artifacts package]]: it's available as a python library
+ [[https://artifacts.readthedocs.io/en/latest/sources/Format-specification.html#][Artifact format]]: this also contains handy URL's for more info on each artifact

Originally based on google/grr, but the repositories have been split out.

+ See [[https://github.com/ForensicArtifacts/artifacts/tree/main/artifacts/data][./artifacts/data/*.yaml]] for a wealth of knowledge about interesting data you
  may find on a system ... potentially indicating vulns, compromise, or just
  day-to-day use.
+ The artifacts intended for Windows/Mac should generally work, but idk if they
  pick up everything on desktop linux. Those intended for server linux should
  generally work, providing you ask SELinux nicely.

*** Google/grr

+ Protobufs in [[https://github.com/google/grr/tree/master/grr/proto/grr_response_proto][./grr/proto/grr_response_proto]]
+ Contains implementation of [[https://github.com/google/grr/blob/master/colab/grr_colab/magics.py][IPython magics]]
+ ForensicArtifacts/artificats provides the yaml definitions synced into
  [[https://github.com/google/grr/tree/master/grr/artifacts][./grr/artifacts/*.yaml]]
+ Service dependencies: [[https://github.com/google/grr/blob/master/compose.yaml][compose.yaml]] for dev and a sample terraform [[https://github.com/google/grr/blob/master/terraform/demo/google/main.tf][main.tf]]

** Resources

*** NSRL

Hash sets for well-known files

+ [[https://www.nist.gov/itl/ssd/software-quality-group/national-software-reference-library-nsrl][National Software Reference Library]]
+ [[https://www.nist.gov/itl/ssd/software-quality-group/national-software-reference-library-nsrl/technical-information/nsrl][NSRL Presentations]]
+ [[https://www.nist.gov/itl/ssd/software-quality-group/national-software-reference-library-nsrl/nsrl-download/current-rds][NSRL Downloads]]


** Topics

*** General CLI Tools

The [[https://docs.remnux.org/][REMnux docs]] and [[https://zeltser.com/remnux-malware-analysis-tips/][this REMnux cheatsheet]] have good overviews on tools that
appear in many distributions.

|-------------------+--------------+-------------+-------------+----------+---------------|
| System : Layer -> | Physical     | Media Mgmnt | File System | File     | App           |
|-------------------+--------------+-------------+-------------+----------+---------------|
| Standard Tools    | lshw         | fdisk       | file        | file     | less/cat/grep |
|                   | lssci        | gdisk       | fsstat      | find     | xv regfmount  |
|                   | hdparm       | file -s     | fls         | ls & etc | display       |
|                   |              | mmls        |             |          |               |
|                   |              | mkfs        |             |          |               |
|-------------------+--------------+-------------+-------------+----------+---------------|
| SiFT/Autopsy/TSK  | tsk_recover  | mmls        | fsstat      | fls      | srch_strings  |
|                   | tsk_gettimes | mmcat       | icat        | fstat    |               |
|                   | sorter       | mmstat      | ils         | fcat     |               |
|                   | img_cat      |             | ifind       | hfind    |               |
|                   | img_stat     |             | istat       |          |               |
|                   | mactime      |             | blkcalc     |          |               |
|                   | sigfind      |             | blkcat      |          |               |
|                   |              |             | blkls       |          |               |
|                   |              |             | blkstat     |          |               |
|                   |              |             | jcat        |          |               |
|                   |              |             | jls         |          |               |
|-------------------+--------------+-------------+-------------+----------+---------------|

The lists of tools are copied from my handwritten notes, but are originally from
SIFT videos and other docs. Most of the descriptions are copied directly from
the man pages.

#+begin_quote
I personally don't have much experience with most of these, which
is why a summary like this would be so useful to me.
#+end_quote

**** LS Star

+ lspci :: list PCI things
+ lsusb :: list USB things
+ lsblk :: list block device things
+ lsscsi :: list SCSI things
+ lsof :: list open file things
+ lshw :: list hardware things
+ lsattr :: list file attributes on a Linux second extended file system
+ chattr :: "cut the chatter. in the byeee... bye bye bye."

**** Linux

+ dmesg :: examine or control the kernel ring buffer
+ free :: display amount of free and used memory in the system
+ udisks :: provides interfaces to enumerate and perform operations on disks and
  storage devices. Operates via a D-Bus API interface, but also includes
  =libudisks2= to provide more direct access to C/C++ programs
+ udisksd :: the =udisks= system daemon
+ udisksctl :: the =udisks= cmdline utility, which interacts with the daemon.
+ udisks2.conf :: the =udisks2= configuration file

**** Physical Layer Utils

+ hdparm :: get/set SATA/IDE device parameters
+ dd :: "convert and copy a file" but usually used to read/write to/from devices
  directly.
+ dc3dd :: patched version of the GNU =dd= tool
+ dcfldd :: an older fork of =dd= (a bit buggy as of 2016)
+ losetup :: set up and control loop devices -- devices virtualized as
  =dev/loop*= that usually contain images copied via =dd=

**** Media Management Layer Utils

+ ddrescue ::
+ fdisk :: manipulate fdisk partition table
+ gdisk :: interactive GUID partition table (GPT) manipulator
+ df :: report file system disk space usage. Included in MML tools because [the
  GNU] version of df cannot show the space available on unmounted file systems,
  because on most kinds of systems doing so requires very nonportable intimate
  knowledge of file system structures

**** Super Shasum Tools For Hashing

+ md5 :: for MD5 hashes
+ sha(.*)sum :: for SHA checksums

**** Input Processing/Filtering

+ file :: determine file type
+ split :: split a file into pieces
  - file-based fanout
+ tee :: for sporking things unless you'd like to foon them
  - input-based fanout
+ cat :: concatenate files and print on the standard output
+ tac :: concat and print files in reverse
+ xxd :: creates a hex dump of a given file or standard input
+ tr :: translate, squeeze, and/or delete characters from standard input,
  writing to standard output.
+ wc :: print newline, word, and byte counts for each file
+ uniq :: this tool is a very special snowflake


**** Network Tools

+ nmcli :: commandline tool for controlling Network Manager
+ netstat :: print network connections, routing tables, interface statistics,
  masquerade connections, and multicast memberships
+ netcat :: cat network things (via sockets, stdin, IPv4, IPv6)
+ ss :: another utility to investigate sockets (dump socket stats; shows
  information similar to netstat, but with more capabilities for OSI layer 4
+ lsof :: listed again since it helps track network files
+ iptables :: administration tool for IPv4/IPv6 packet filtering and NAT
+ nft :: to set up, maintain and inspect packet filtering and classification
  rules in the Linux kernel, in the nftables framework. The Linux kernel
  subsystem is known as nf_tables, and ‘nf’ stands for Netfilter

**** EWF Format

+ Install with =pacman -Syu libewf=. Installed on Tsurugi by default, which is
  typically where you want to do this stuff..

Used to bolster the validation of chain of custody and/or data
provenance.[fn:ewfformat] Can enable working with parts of compressed images
without decompressing the whole, which as I understand it may make it difficult
for on-image scripts to modify the image itself, were they capable of waking up
and doing so. The workflow for Org files for and On arch,

+ ewfacquire :: acquire data in the EWF format
+ ewfacquirestream :: from =stdin=, acquire data in the EWF format
+ ewfexport :: exports media data stored in EWF files
+ ewfinfo :: show metadata stored in EWF files
+ ewfmount :: mount data stored in EWF files
+ ewfrecover :: exports media data stored in EWF files which may be recovered if corrupted
+ ewfverify :: verifies media data stored in EWF files
+ ewfdebug :: debug EWF things?

**** AFF Format

+ aimage :: create copies of devices in AFF format

**** Misc

+ bc :: an arbitrary precision calculator language for shell script calculations

*** Audio Forensics

+ [[https://enfsi.eu/wp-content/uploads/2022/12/FSA-BPM-002_BPM-for-Digital-Audio-Authenticity-Analysis.pdf][ENFSI Digital Audio Authenticity Analysis Best Practice Manual]]

**** Recording Authenticity

+ [[https://www.montana.edu/rmaher/publications/maher_forensics_chapter_2010.pdfhttps://www.montana.edu/rmaher/publications/maher_forensics_chapter_2010.pdf][Overview of Audio Forensics]]
+ [[https://www.soundonsound.com/techniques/introduction-forensic-audio][Sound on Sound: Intro to Forensic Audio]]
+ [[http://acousticstoday.org/wp-content/uploads/2015/08/Lending-an-Ear-in-the-Courtroom-Forensic-Acoustics-Forensic-acoustics-deals-with-acquisition-analysis-and-evaluation-of-audio-recordings-to-be-used-as-evidence-in-an-official-legal-inquiry..pdf][Lending an ear in the courtroom: forensic acoustics]]


*** Timeline
**** Plaso
Originally, log2timeline/log2timeline

* Digital Forensics Distros

Forensic distributions include SiFT workstation, [[https://tsurugi-linux.org/][Tsurugi Linux]] and others. These
have been collected and curated by the folks at [[https://www.sans.org/tools/sift-workstation/][SANS]]. Tons of info can be found
on their website and [[https://www.youtube.com/user/robtlee73][youtube channel]]. Their cheatsheets are pretty awesome.

Sadly, the SiFT docker image is no longer well-maintained. Also, the last time I
heavily used Tsurugi/SiFT, a direct install (not a VM) was the best way to go
for this, although I would love to get some feedback on that. At least one
reason here is to containerize your forensics workflow, so that it's tougher for
externalities to interfere.

** Remnux

+ [[https://docs.remnux.org/run-tools-in-containers/remnux-containers][Remnux Containers]]

REMnux is one of the better known toolkits for malware analysis, usually post-mortem.


** Paladin

** SIFT

** Tsurugi


** Ansible

+ [[https://github.com/robertdebock/ansible-role-forensics][robertdebock/ansible-role-forensics]]
+ [[https://github.com/jgru/ansible-forensic-workstation][jgru/ansible-forensic-workstation]]


* Digital Forensics Software

** SleuthKit (TSK)

*** Docs
+ [[https://sleuthkit.org/sleuthkit][Main]]
+ [[PSA: upgrade your LUKS key derivation function][TSK Books/Courses]]
+ [[https://sleuthkit.org/sleuthkit/desc.php][Volumes/FS Analysis]]
+ [[https://wiki.sleuthkit.org/index.php?title=TSK_Tool_Overview][TSK Tools]] overview of CLI tools

*** Resources
+ [[https://wiki.sleuthkit.org/index.php?title=FS_Analysis][FS Analysis]] (raw block devices)

*** Topics

*** Issues

** Autopsy

Autopsy is a graphical interface to TSK.

#+begin_quote
Autopsy is probably overkill for deduplicating files... which is what I need it
for. Might as well see what else it can do.

[[https://www.tecmint.com/find-and-delete-duplicate-files-in-linux/][Other file deduplication tools]]: rdfind, fdupes, rmlint, dupeguru, fslint
#+end_quote

*** Docs

+ [[https://sleuthkit.org/autopsy/][Main]]
+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.21.0/][User Docs]]
+ [[https://sleuthkit.org/autopsy/docs/api-docs/4.21.0//][Developer's Guide]]
+ [[https://sleuthkit.org/autopsy/features.php][Features]]
+ [[https://sleuthkit.org/autopsy/docs/user-docs/3.1/hash_db_page.html][Hash Database]]

Note: some of the links here are for =4.15.0= not =4.20.0=

**** Features

+ EXIF extraction
+ Case Tracking (collaboration, timelines, reports, chain of custody, etc)
+ Unicode strings extraction :: Extract strings from unallocated space
+ File Type Detection :: analyze disk images for metadata and magic numbers
+ Email Analysis :: Parse emails in MBOX format
  - Apparently Thunderbird uses the same same format that some Emacs email
    packages use ... which is very nice to know, since setting all the
    automation for that can be a lot of work ([[https://stackoverflow.com/questions/42618010/moving-from-thunderbird-to-emacs-mu4e][nevermind ...]] thunderbird
    introduces some customizations to its mbox format)

**** Usage

+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/auto_ingest_setup_page.html][Auto Ingest Configuration]]
+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/ds_page.html][Data Sources]] adding disks/images and configuring the tasks to run on them
+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/file_discovery_page.html][File Discovery]] filter on files (including hashes for dedupe)
+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/communications_page.html][Communications Visualization]]
+ [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/interesting_files_identifier_page.html][Interesting Files Identification]]

*** Resources

*** Topics

**** Modules

The autopsy modules are now here [[https://github.com/sleuthkit/autopsy_addon_modules][sleuthkit/autopsy_addon_modules]] which contains
many more than the wiki page.

***** [[https://github.com/sleuthkit/autopsy_addon_modules/tree/master/IngestModules/Create_Datasource_Hashset][IngestModules/Create_Datasource_Hashset]]

#+begin_quote
Create a hashset of a data source, the hashset is stored in the case export
directory. The datasource must be hashed prior to running this plugin. The
hashset can then be brought back into Autopsy.
#+end_quote

***** Kafka Viewer

[[github:tomwayne1984/autopsy_kafka_forensics][tomwayne1984/autopsy_kafka_forensics]]

#+begin_quote
Kafka Log Forensic is a Data Content Viewer for the big data streaming software
Apache Kafka. It allows the user to view records stored cluster-side in Apache
Kafka log files.
#+end_quote

hmmmm... that's interesting. I wonder if Elon ran that on Twitter? ...

**** Hash Database

***** [[https://sleuthkit.org/autopsy/docs/user-docs/4.15.0/hash_db_page.html][Hash Lookup]] module

+ [[https://sleuthkit.discourse.group/t/autopsy-4-19-3-hash-not-calculeted/3339][Running Ingest Module to Create Hash Set]] screenshots for walking through the
  hash lookup tool.

***** Hash Set Formats


| *.txt  | Text        | One hash starting each line.                                    |
| *.idx  | Index only  | Generated by Sleuth Kit/Autopsy (NSRL available in this format) |
| *.kdb  | TSK/Autopsy | SQLite hash sets created by Autopsy                             |
| *.hash | EnCase      | An EnCase hash set file                                         |
| *.hsh  | HashKeeper  | Hash set file conforming to the HashKeeper standard             |

+ Text Format: the output from running the md5, md5sum, or md5deep program on a
  set of files. The hash begins the line.

***** [[https://sleuthkit.org/autopsy/docs/user-docs/4.20.0/discovery_page.html#file_disc_dedupe][Deduplication]]

Use the hash lookup. Autopsy can be configured to use a Postgres database, so:

+ Ingest data sources and generate hash database
+ Build sets of useful filters
+ Analyze the Postgres table metadata to determine schema
+ identify the queries that correspond to the filters
+ Query postgres to eliminate duplicates that also exist on the new disk
+ Extract a list of paths

**** Old Modules List

+ [[https://wiki.sleuthkit.org/index.php?title=Autopsy_3rd_Party_Modules][Autopsy 3rd party plugins]]
+ [[https://github.com/williballenthin/Autopsy-WindowsRegistryContentViewer][williballenthin/Autopsy-WindowsRegistryContentViewer]]
+ [[http://www.cybertriage.com/][Cyber Triage]] automates collection and analysis to determine whether host (live
  or dead) is compromised

***** [[https://github.com/markmckinnon/Autopsy-Plugins][markmckinnon/Autopsy-Plugins]]

Python Plugins

| Amazon Echosystem Parser | SAM Parse                    | Process Extract VSS    |
| CCM RecentlyUsedApps     | Parse Shellbags              | Process SRUDB          |
| Cuckoo                   | Parse SQLite Databases       | Shimcache Parser       |
| File History             | Parse SQLite Deleted Records | Thumbcache Parser      |
| Jump_List_AD             | Parse USNJ                   | Thumbs.db Parser       |
| MacFSEvents              | Plaso                        | Volatility             |
| MacOSX Recent            | Process Amcache              | Webcache               |
| MacOSX Safari            | Process EVTX                 | Windows Internals      |
| Plist Parser             | Process EVTX By EventID      | Process Prefetch Files |

***** [[https://github.com/pcbje/autopsy-ahbm][pcbje/autopsy-ahbm]]

Use sdhash to perform fuzzy hash matching

#+begin_quote
The investigator can match files against other files or sdhash reference sets
during ingest, or search for similar files from the directory viewer or search
results after ingest
#+end_quote

***** [[https://github.com/tomvandermussele/autopsy-plugins][tomvandermussele/autopsy-plugins]]

Other python plugins

+ Connected iPhones (Connected iPhone Analyzer)
+ Skype (Skype Analyzer)
+ IE Tiles
+ Google Drive
+ Google Chrome Saved Passwords Identifier
+ Windows Communication App Contact Extractor

***** [[https://github.com/LoWang123/ImageFingerprintModulePackage][LoWang123/ImageFingerprintModulePackage]]

Generate a database of perceptual hashes from images, so images can be searched
for similarity (under some conditions)

*** Issues


* Footnotes

+ [fn:ewfformat] Refining evidence containers for provenance and accurate data representation (doi: [[https://link.springer.com/content/pdf/10.1007%2F978-3-642-15506-2_16.pdf][10.1007/978-3-642-15506-2_16]])
